# Hippos 高性能上下文管理服务架构设计文档

## 文档信息

- **项目名称**：Hippos（亦称 Mantle/Atollo）
- **版本**：v1.1.0
- **文档状态**：修订版（根据评审建议增补）
- **编制日期**：2026年1月10日
- **修订日期**：2026年1月10日

---

## 一、系统概述

### 1.1 项目定位与核心价值

Hippos 定位为一款独立部署、高性能运行的上下文管理服务，其核心使命是解决大语言模型在长对话场景中面临的上下文窗口限制问题。在实际的 AI Agent 应用中，随着对话轮次的不断增加，模型往往会出现"失忆"现象——遗忘早期讨论的重要细节，或者因上下文超出限制而产生"幻觉"，编造出不准确的信息。Hippos 通过构建类似人类认知系统的"工作记忆"与"长期记忆"切换机制，为 AI Agent 提供持久化的对话记忆能力。

本服务的核心价值主张体现在三个维度：首先是**无限会话感知**，通过全量存储机制确保每一轮对话的原始内容都被完整保留，突破模型上下文窗口的物理限制；其次是 **Token 成本优化**，采用"渐进式披露"策略，仅在 Agent 明确需要时才加载详细历史内容，显著降低平均 Token 消耗；第三是**会话隔离安全**，严格的多租户架构确保不同会话之间的数据完全独立，满足企业级应用的安全合规要求。

### 1.2 核心设计理念

Hippos 的设计灵感源自人类认知系统的记忆机制。人类的记忆系统并非将所有感知信息全部存储，而是通过海马体进行信息筛选，将重要信息编码后转移到大脑皮层形成长期记忆，在需要时再进行提取和整合。Hippos 借鉴这一机制，将原始对话"脱水"为轻量级的索引记录，仅保留摘要、主题标签和语义向量，而将完整内容作为"长期记忆"按需挂载。

"全量存储、渐进索引、按需挂载"这一设计哲学贯穿整个系统架构。全量存储确保数据的完整性和可追溯性，为后续的检索和分析提供坚实基础；渐进索引通过多层次的索引结构，支持从快速浏览到精确检索的不同粒度需求；按需挂载则实现了计算资源的按需分配，避免不必要的内存占用和带宽消耗。

---

## 二、架构设计原则

### 2.1 性能优先原则

系统架构的每一个决策都将性能指标作为首要考量因素。根据 PRD 定义的 P99 延迟小于 10ms 的严格要求，架构设计需要从数据结构的选型、索引策略的优化、网络传输的精简等多个维度进行综合考量。具体而言，核心检索路径必须规避任何可能导致阻塞的操作，包括但不限于同步 I/O、外部服务调用、复杂计算等。所有可能影响响应延迟的操作都必须采用异步化处理或预处理策略。

### 2.2 多租户隔离原则

会话隔离是 Hippos 的核心安全特性，必须在存储层、索引层和检索层三个层面得到严格保障。存储层的隔离确保不同会话的数据物理或逻辑分离，防止越权访问；索引层的隔离确保向量空间相互独立，避免跨会话的语义干扰；检索层的隔离通过权限校验机制，确保每个会话只能访问其授权范围内的数据。

### 2.3 渐进式复杂度原则

架构设计遵循"先简单后复杂"的演进路径。初期实现采用单一存储引擎和简化的索引策略，在验证核心功能后再根据实际负载情况进行分层存储或分布式扩展的演进。这一原则要求所有模块设计都必须具备清晰的演进边界，在不影响现有接口的前提下支持未来的功能增强和性能优化。

### 2.4 协议兼容原则

作为 MCP（Model Context Protocol）兼容的服务，Hippos 的 API 设计必须遵循协议规范，确保与主流 AI Agent 框架的无缝集成。协议兼容性不仅体现在接口格式上，更包括错误处理、超时机制、重试策略等细节行为的一致性。

---

## 三、系统架构总览

### 3.1 分层架构设计

Hippos 采用经典的分层架构设计，自下而上依次为存储层、索引层、服务层和接入层。每一层都有明确的职责边界，层与层之间通过定义良好的接口进行通信。

```
┌─────────────────────────────────────────────────────────────┐
│                        接入层 (API Layer)                    │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────────────┐  │
│  │  MCP Server │  │  REST API   │  │  gRPC Interface     │  │
│  └─────────────┘  └─────────────┘  └─────────────────────┘  │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                        服务层 (Service Layer)                │
│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────┐  │
│  │  会话管理服务    │  │  检索引擎服务    │  │  索引服务    │  │
│  │  SessionManager │  │  RetrievalSvc   │  │  IndexSvc   │  │
│  └─────────────────┘  └─────────────────┘  └─────────────┘  │
│  ┌─────────────────┐  ┌─────────────────┐                   │
│  │  脱水处理服务    │  │  权限校验服务    │                   │
│  │  DehydrationSvc │  │  AuthSvc        │                   │
│  └─────────────────┘  └─────────────────┘                   │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                        索引层 (Index Layer)                  │
│  ┌─────────────────────────────────────────────────────┐    │
│  │              向量索引引擎 (Vector Index)              │    │
│  │    [Session-A Space]  [Session-B Space]  ...        │    │
│  └─────────────────────────────────────────────────────┘    │
│  ┌─────────────────────────────────────────────────────┐    │
│  │              全文索引引擎 (Full-Text Index)           │    │
│  │    [Session-A FTS]  [Session-B FTS]  ...            │    │
│  └─────────────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                        存储层 (Storage Layer)                │
│  ┌─────────────────────────────────────────────────────┐    │
│  │              主存储引擎 (SurrealDB/LanceDB)           │    │
│  │  ┌───────────┐  ┌───────────┐  ┌─────────────────┐ │    │
│  │  │ 原始对话库 │  │ 索引元数据 │  │ 会话配置库      │ │    │
│  │  │ RawTexts  │  │ IndexMeta  │  │ SessionConfig  │ │    │
│  │  └───────────┘  └───────────┘  └─────────────────┘ │    │
│  └─────────────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────┘
```

### 3.2 组件交互关系

接入层负责处理外部请求，目前规划支持三种接入方式：MCP 协议适配器、RESTful API 和 gRPC 接口。MCP 适配器是核心接入方式，直接对接 AI Agent 工具调用；REST API 用于管理操作和调试；gRPC 接口则为高性能场景提供更低延迟的选择。

服务层是业务逻辑的核心所在，包含五个主要服务组件。会话管理服务负责会话的创建、销毁和生命周期管理；检索引擎服务处理所有的索引查询和内容获取请求；索引服务管理索引的创建、更新和删除；脱水处理服务负责对话内容的摘要提取和向量化；权限校验服务实施会话隔离的访问控制策略。

索引层提供高速检索能力，向量索引引擎采用基于 IVF（Inverted File）结构的近似最近邻搜索算法，全文索引引擎支持中文分词和语义扩展。索引层与存储层紧密配合，索引数据从存储层派生，但为检索路径提供更高效的查询性能。

存储层是数据的最终归宿，采用 SurrealDB 或 LanceDB 作为主存储引擎，同时承担原始内容存储、索引元数据存储和会话配置存储的职责。存储层还需要支持数据持久化和故障恢复。

### 3.3 数据流概览

系统存在两条主要的数据流路径：写入路径和读取路径。写入路径从对话内容的接收开始，经过脱水处理生成摘要和向量，再更新索引结构，最后持久化存储。读取路径从检索请求开始，首先查询索引获取候选记录，再进行权限校验，最后返回结果或完整内容。两条路径的设计需要平衡一致性和性能，通常采用最终一致性模型来优化写入路径的响应时间。

---

## 四、核心模块设计

### 4.1 存储层设计

#### 4.1.1 会话隔离机制

会话隔离是 Hippos 安全架构的基石，采用三层隔离策略实现完整的数据保护。

**第一层：Namespace 隔离**。利用 SurrealDB 的 Namespace 特性，每个会话对应一个独立的 Namespace。Namespace 之间完全隔离，查询范围默认限制在当前 Namespace 内，跨 Namespace 的查询需要显式的授权配置。这一层隔离提供了最强的安全边界，适用于多租户场景下的租户级隔离。

```rust
// Namespace 隔离示意代码
impl SessionManager {
    pub async fn create_session(&self, tenant_id: &str) -> Result<Session, Error> {
        let ns_name = format!("sess_{}", tenant_id);
        // 创建新 Namespace
        self.db.query(format!("DEFINE NAMESPACE {}", ns_name)).await?;
        
        // 初始化会话数据库
        self.db.use_ns(&ns_name).use_db("sessions").await?;
        
        // 在新 Namespace 中创建会话表
        self.db.query("DEFINE TABLE turn CONTENT { schemafull: true }").await?;
        
        Ok(Session { namespace: ns_name, .. })
    }
}
```

**第二层：表级隔离**。在同一 Namespace 内，通过表名设计实现会话间的逻辑隔离。所有会话表名都包含会话标识前缀，如 `turn_session_a`、`turn_session_b`，确保即便在同一 Namespace 内的误操作也不会影响其他会话数据。

**第三层：字段级隔离**。对于需要更细粒度控制的场景，在记录级别添加所有者标识字段，查询时强制附加所有权过滤条件。这一层主要用于处理特殊的委托访问场景。

#### 4.1.2 数据模型设计

系统的数据模型围绕三个核心实体设计：会话（Session）、对话轮次（Turn）和索引记录（IndexRecord）。

**会话实体**承载会话的元数据信息，包括创建时间、最后活跃时间、会话配置参数等。会话实体是数据访问的根节点，所有对对话内容的访问都必须通过会话实体进行授权验证。

```typescript
interface Session {
    // 会话唯一标识，由系统生成
    id: string;
    
    // 所属租户/用户标识
    tenant_id: string;
    
    // 会话创建时间（毫秒级精度）
    created_at: number;
    
    // 最后活跃时间
    last_active_at: number;
    
    // 会话配置
    config: {
        // 保留的摘要数量
        summary_limit: number;
        // 索引刷新间隔
        index_refresh_interval: number;
        // 是否启用语义搜索
        semantic_search_enabled: boolean;
    };
    
    // 统计信息
    stats: {
        total_turns: number;
        total_tokens: number;
        storage_size: number;
    };
}
```

**对话轮次实体**存储每一轮对话的完整信息，是系统的核心数据实体。每个轮次记录包含原始内容、时间戳、关联的主题标签和脱水后的摘要信息。

```typescript
interface Turn {
    // 轮次唯一标识，格式为 turn_{session_id}_{timestamp}
    id: string;
    
    // 所属会话ID
    session_id: string;
    
    // 轮次序号
    turn_number: number;
    
    // 原始对话内容（Markdown格式）
    raw_content: string;
    
    // 元数据
    metadata: {
        // 精确到毫秒的时间戳
        timestamp: number;
        
        // 用户标识
        user_id?: string;
        
        // 消息类型
        message_type: 'user' | 'assistant' | 'system';
    };
    
    // 脱水后的摘要信息
    dehydrated: {
        // 50-100字的极简概括
        gist: string;
        
        // 核心讨论主题
        topics: string[];
        
        // 关键词标签
        tags: string[];
        
        // 语义向量（384或768维度）
        embedding: number[];
        
        // 摘要生成时间
        generated_at: number;
    };
    
    // 内容状态
    status: 'pending' | 'indexed' | 'archived';
}
```

**索引记录实体**是脱水处理后的轻量级数据结构，专门为高速检索优化。索引记录与对话轮次一一对应，但存储结构针对查询模式进行了优化。

```typescript
interface IndexRecord {
    // 关联的对话轮次ID
    turn_id: string;
    
    // 会话ID（用于快速过滤）
    session_id: string;
    
    // 摘要文本
    gist: string;
    
    // 主题列表
    topics: string[];
    
    // 标签列表
    tags: string[];
    
    // 时间戳
    timestamp: number;
    
    // 向量标识（指向向量存储的具体位置）
    vector_id: string;
    
    // 检索相关性评分（预计算）
    relevance_score?: number;
}
```

#### 4.1.3 存储引擎选型

根据 PRD 的技术约束和性能要求，推荐采用 SurrealDB 作为主存储引擎，LanceDB 作为向量检索的辅助引擎。

**SurrealDB 选型理由**如下。首先 SurrealDB 是原生 Rust 实现，天然契合项目的技术栈要求，能够实现极致的内存安全和并发性能。第二 SurrealDB 是多模态数据库，同时支持关系模型、文档模型、图模型和向量搜索，一套存储系统即可满足所有数据存储需求。第三 SurrealDB 的 SurrealQL 查询语言功能强大，支持复杂的关联查询和过滤条件。第四 SurrealDB 支持 Namespace 和 Database 级别的多租户隔离，与系统设计高度契合。最后 SurrealDB 支持嵌入模式（In-Memory 或 File-Based），便于轻量级部署。

**向量存储补充方案**。对于向量检索性能有极致要求的场景，可以引入 LanceDB 作为专用的向量索引引擎。LanceDB 在向量搜索方面具有显著性能优势，支持数十亿级向量的毫秒级检索，且提供零-copy 操作和 GPU 加速能力。两种引擎的协作模式是：SurrealDB 存储完整数据和控制信息，LanceDB 存储向量索引并提供高速检索服务。

```rust
// 混合存储架构示意
struct HybridStorage {
    // 主存储：SurrealDB，用于完整数据存储和事务控制
    surrealdb: Surreal<Ws>,
    
    // 向量索引：LanceDB，用于高速向量检索
    lancedb: Arc<Connection>,
    
    // 嵌入模型
    embedding_model: Arc<dyn EmbeddingModel>,
}

impl HybridStorage {
    pub async fn store_turn(&self, turn: &Turn) -> Result<(), Error> {
        // 1. 生成摘要和向量
        let gist = self.generate_gist(&turn.raw_content).await?;
        let embedding = self.embedding_model.encode(&gist).await?;
        
        // 2. 存储原始数据到 SurrealDB
        self.surrealdb
            .update(("turn", &turn.id))
            .content(turn)
            .await?;
        
        // 3. 存储向量到 LanceDB
        let vector_id = format!("vec_{}", turn.id);
        self.lancedb.execute(&format!(
            "INSERT INTO vector_index (id, vector, metadata) VALUES ('{}', {}, '{{}}')",
            vector_id,
            embedding.iter().collect::<Vec<_>>()
        )).await?;
        
        Ok(())
    }
}
```

### 4.2 索引引擎设计

#### 4.2.1 动态索引架构

索引系统采用双层架构设计：第一层是面向高速检索的倒排索引和向量索引，第二层是面向复杂查询的全文索引。这种设计平衡了检索性能和功能丰富度。

**倒排索引层**存储主题标签和关键词的映射关系，支持快速的精确匹配和时间范围筛选。倒排索引按会话隔离，每个会话拥有独立的倒排表空间。索引结构设计如下：

```rust
// 倒排索引结构
struct InvertedIndex {
    // 主题 -> 轮次ID列表的映射
    topic_index: HashMap<String, Vec<String>>,
    
    // 标签 -> 轮次ID列表的映射  
    tag_index: HashMap<String, Vec<String>>,
    
    // 时间范围索引（按小时分桶）
    time_index: BTreeMap<u64, Vec<String>>,
    
    // 每个会话的倒排索引（会话内隔离）
    session_indices: HashMap<String, SessionInvertedIndex>,
}

struct SessionInvertedIndex {
    // 会话ID
    session_id: String,
    
    // 会话内的倒排索引
    topic_index: HashMap<String, Vec<String>>,
    tag_index: HashMap<String, Vec<String>>,
    time_index: BTreeMap<u64, Vec<String>>,
    
    // 最后更新时间
    last_updated: u64,
}
```

**向量索引层**存储语义向量的近似最近邻索引，支持基于语义的模糊检索。向量索引采用 IVF-PQ（Inverted File with Product Quantization）算法，在检索精度和速度之间取得良好平衡。索引参数配置如下：

```rust
// 向量索引配置
struct VectorIndexConfig {
    // 向量维度（384或768）
    dimension: usize,
    
    // IVF 聚类数量
    nlist: usize,
    
    // 查询时返回的候选数量
    nprobe: usize,
    
    // 产品量化因子
    pq_m: usize,
    
    // 距离计算方式
    distance_type: DistanceType,
}

impl Default for VectorIndexConfig {
    fn default() -> Self {
        Self {
            dimension: 384,  // 采用较小维度以平衡性能和存储
            nlist: 1024,      // 聚类数量，根据数据规模调整
            nprobe: 32,       // 查询时搜索的聚类数
            pq_m: 8,          // PQ 分段数
            distance_type: DistanceType::Cosine,
        }
    }
}
```

**全文索引层**支持基于关键词的全文检索，采用分词+倒排索引的方式实现。全文索引主要用于摘要内容的检索，支持中文分词和词干提取。

#### 4.2.2 渐进式披露机制

渐进式披露是 Hippos 的核心交互模式，系统在不同的对话阶段提供不同粒度的信息。

**感知阶段**仅提供索引列表，即脱水后的摘要目录。索引列表包含轮次ID、摘要 gist、主题标签和时间戳，不包含原始内容。

```rust
impl IndexService {
    pub async fn list_indices(
        &self,
        session_id: &str,
        request: ListIndicesRequest,
    ) -> Result<ListIndicesResponse, Error> {
        // 1. 验证会话访问权限
        self.validate_session_access(session_id)?;
        
        // 2. 根据请求参数构建查询
        let query = self.build_index_query(session_id, &request)?;
        
        // 3. 执行索引查询（不涉及原始内容）
        let indices: Vec<IndexRecord> = self.index_store.query(query).await?;
        
        // 4. 转换为渐进式披露格式
        let progressive_indices: Vec<ProgressiveIndex> = indices
            .into_iter()
            .map(|idx| ProgressiveIndex {
                turn_id: idx.turn_id,
                gist: idx.gist,
                topics: idx.topics,
                timestamp: idx.timestamp,
                disclosure_level: DisclosureLevel::Summary,  // 默认仅披露摘要
            })
            .collect();

        Ok(ListIndicesResponse {
            indices: progressive_indices,
            total_count: self.count_indices(session_id).await?,
        })
    }
}
```

**挂载阶段**提供完整内容。当 Agent 通过 `fetch_content` 请求特定轮次的内容时，系统执行权限校验后返回原始数据。

```rust
impl RetrievalService {
    pub async fn fetch_content(
        &self,
        session_id: &str,
        turn_id: &str,
    ) -> Result<FetchContentResponse, Error> {
        // 1. 严格的权限校验：turn_id 必须归属于 session_id
        let turn = self.validate_ownership(session_id, turn_id)?;
        
        // 2. 记录访问日志
        self.audit_log.record(session_id, turn_id, "content_fetch");
        
        // 3. 返回完整内容
        Ok(FetchContentResponse {
            turn_id: turn.id,
            raw_content: turn.raw_content,
            metadata: turn.metadata,
            disclosure_level: DisclosureLevel::Full,
        })
    }
}
```

### 4.3 检索引擎设计

#### 4.3.1 双阶段检索流程

检索引擎采用"索引匹配+内容获取"的双阶段设计，第一阶段快速筛选候选记录，第二阶段按需获取详细内容。

**第一阶段：索引检索**。这一阶段的目标是快速从海量对话中找到最相关的记录，返回的是轻量级的索引列表（包含摘要而非原文）。索引检索支持三种模式：

```rust
impl RetrievalService {
    // 默认视图：返回最近的N条摘要索引
    pub async fn list_recent(
        &self,
        session_id: &str,
        limit: u32,
    ) -> Result<Vec<IndexRecord>, Error> {
        self.index_store
            .query(&format!(
                "SELECT * FROM index_record 
                 WHERE session_id = '{}' 
                 ORDER BY timestamp DESC 
                 LIMIT {}",
                session_id, limit
            ))
            .await
    }
    
    // 时间回溯：按时间区间筛选
    pub async fn list_by_time_range(
        &self,
        session_id: &str,
        start_time: u64,
        end_time: u64,
    ) -> Result<Vec<IndexRecord>, Error> {
        self.index_store
            .query(&format!(
                "SELECT * FROM index_record 
                 WHERE session_id = '{}' 
                 AND timestamp >= {} AND timestamp <= {} 
                 ORDER BY timestamp DESC",
                session_id, start_time, end_time
            ))
            .await
    }
    
    // 语义搜索：基于向量相似度检索
    pub async fn semantic_search(
        &self,
        session_id: &str,
        query_text: &str,
        limit: u32,
    ) -> Result<Vec<IndexRecord>, Error> {
        // 1. 将查询文本编码为向量
        let query_vector = self.embedding_model.encode(query_text).await?;
        
        // 2. 在会话的向量空间中检索
        let results = self.vector_index
            .search_session(session_id, &query_vector, limit)
            .await?;
        
        // 3. 转换为索引记录
        let indices = self.load_index_records(results).await?;
        
        Ok(indices)
    }
}
```

**第二阶段：内容获取**。这一阶段根据第一阶段返回的 `turn_id` 列表，从存储层获取完整的对话内容。每次内容获取都强制执行权限校验。

```rust
impl RetrievalService {
    pub async fn fetch_batch_content(
        &self,
        session_id: &str,
        turn_ids: &[String],
    ) -> Result<Vec<Turn>, Error> {
        // 1. 批量校验所有权
        for turn_id in turn_ids {
            self.validate_ownership(session_id, turn_id)?;
        }
        
        // 2. 批量加载原始数据
        let turns: Vec<Option<Turn>> = self.surrealdb
            .query(&format!(
                "SELECT * FROM turn WHERE id INSIDE {}",
                serde_json::to_string(turn_ids)?
            ))
            .await?;
        
        // 3. 过滤掉越权访问的记录（防御性编程）
        let valid_turns: Vec<Turn> = turns
            .into_iter()
            .flatten()
            .filter(|t| t.session_id == session_id)
            .collect();
        
        Ok(valid_turns)
    }
}
```

#### 4.3.2 混合检索策略

为了获得最佳的检索效果，系统支持将多种检索策略组合使用。

**时间加权检索**：将时间因素纳入相关性评分，越近期的对话具有更高的权重。

```rust
struct TimeWeightedSearch {
    vector_similarity_weight: f32,
    recency_weight: f32,
    decay_half_life: u64,  // 半衰期（小时）
}

impl TimeWeightedSearch {
    pub fn compute_score(
        &self,
        vector_score: f32,
        timestamp: u64,
    ) -> f32 {
        let recency_score = (-(now() - timestamp) as f32 
            / (self.decay_half_life * 3600) as f32).exp();
        
        self.vector_similarity_weight * vector_score 
            + self.recency_weight * recency_score
    }
}
```

**混合搜索**：结合向量相似度和关键词匹配的结果，使用 Reciprocal Rank Fusion 算法融合排名。

```rust
pub async fn hybrid_search(
    &self,
    session_id: &str,
    query: &str,
    limit: u32,
) -> Result<Vec<SearchResult>, Error> {
    // 并行执行向量搜索和关键词搜索
    let (vector_results, fts_results) = tokio::join!(
        self.vector_search(session_id, query, limit * 2),
        self.full_text_search(session_id, query, limit * 2)
    );
    
    // 使用 RRF 融合排名
    let fused_results = Self::reciprocal_rank_fusion(
        &vector_results?,
        &fts_results?,
        limit,
    );
    
    Ok(fused_results)
}

// Reciprocal Rank Fusion 算法
fn reciprocal_rank_fusion(
    vector_results: &[IndexRecord],
    fts_results: &[IndexRecord],
    k: u32,
) -> Vec<SearchResult> {
    let mut score_map: HashMap<&str, f32> = HashMap::new();
    
    // 向量搜索排名得分
    for (rank, record) in vector_results.iter().enumerate() {
        let rrf_score = 1.0 / (k + rank as u32 + 1);
        *score_map.entry(&record.turn_id).or_insert(0.0) += rrf_score;
    }
    
    // FTS 排名得分
    for (rank, record) in fts_results.iter().enumerate() {
        let rrf_score = 1.0 / (k + rank as u32 + 1);
        *score_map.entry(&record.turn_id).or_insert(0.0) += rrf_score;
    }
    
    // 按综合得分排序
    let mut results: Vec<_> = score_map.into_iter().collect();
    results.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());
    
    results.into_iter()
        .map(|(turn_id, score)| SearchResult { turn_id, score })
        .take(limit as usize)
        .collect()
}
```

### 4.4 API 层设计

#### 4.4.1 MCP 协议适配

系统核心 API 遵循 MCP（Model Context Protocol）规范设计，确保与主流 AI Agent 框架的无缝集成。MCP 协议的核心概念包括 Tools（工具）、Resources（资源）和 Prompts（提示模板），Hippos 主要通过 Tools 接口暴露其功能。

**工具定义**（tools/list 响应）：

```json
{
  "tools": [
    {
      "name": "list_recent_indices",
      "title": "List Recent Conversation Indices",
      "description": "Retrieve the most recent conversation summaries for the current session, providing a progressive disclosure of context without loading full content.",
      "inputSchema": {
        "type": "object",
        "properties": {
          "limit": {
            "type": "integer",
            "description": "Maximum number of indices to return (default: 10, max: 100)",
            "minimum": 1,
            "maximum": 100
          },
          "session_id": {
            "type": "string",
            "description": "Session identifier (auto-detected in most cases)"
          }
        },
        "required": []
      },
      "outputSchema": {
        "type": "object",
        "properties": {
          "indices": {
            "type": "array",
            "description": "List of conversation indices with summaries"
          },
          "total_count": {
            "type": "integer",
            "description": "Total number of indices available"
          }
        }
      }
    },
    {
      "name": "search_indices",
      "title": "Search Conversation Indices",
      "description": "Search for conversation indices using semantic similarity or keywords within the current session. Returns a list of relevant conversation summaries.",
      "inputSchema": {
        "type": "object",
        "properties": {
          "query": {
            "type": "string",
            "description": "Search query text or semantic description"
          },
          "limit": {
            "type": "integer",
            "description": "Maximum number of results (default: 10, max: 50)"
          },
          "time_range": {
            "type": "object",
            "description": "Optional time range filter"
          }
        },
        "required": ["query"]
      }
    },
    {
      "name": "fetch_turn_content",
      "title": "Fetch Conversation Content",
      "description": "Retrieve the full original content of a specific conversation turn. Performs ownership verification before returning content.",
      "inputSchema": {
        "type": "object",
        "properties": {
          "turn_id": {
            "type": "string",
            "description": "The unique identifier of the conversation turn to retrieve"
          },
          "session_id": {
            "type": "string",
            "description": "Session identifier (auto-detected in most cases)"
          }
        },
        "required": ["turn_id"]
      }
    },
    {
      "name": "store_turn",
      "title": "Store Conversation Turn",
      "description": "Store a new conversation turn with automatic summarization and indexing. Returns the generated turn_id.",
      "inputSchema": {
        "type": "object",
        "properties": {
          "content": {
            "type": "string",
            "description": "The conversation content to store (Markdown format)"
          },
          "timestamp": {
            "type": "integer",
            "description": "Optional timestamp in milliseconds (defaults to current time)"
          },
          "metadata": {
            "type": "object",
            "description": "Optional metadata for the conversation turn"
          }
        },
        "required": ["content"]
      }
    }
  ]
}
```

**工具调用请求/响应格式**（遵循 MCP 规范）：

```json
// 请求示例：搜索对话索引
{
  "jsonrpc": "2.0",
  "id": 3,
  "method": "tools/call",
  "params": {
    "name": "search_indices",
    "arguments": {
      "query": "重构方案的技术细节",
      "limit": 5
    }
  }
}

// 响应示例
{
  "jsonrpc": "2.0",
  "id": 3,
  "result": {
    "content": [
      {
        "type": "text",
        "text": "{\"indices\": [{\"turn_id\": \"turn_sess_abc_102\", \"gist\": \"讨论了使用 Rust 改写中间件的方案，涉及异步运行时选择和错误处理模式\", \"topics\": [\"代码重构\", \"Rust\", \"中间件\"], \"timestamp\": 1704931200000}], \"total_count\": 1}"
      }
    ],
    "isError": false
  }
}
```

#### 4.4.2 REST API 设计

除 MCP 接口外，系统还提供 REST API 用于管理操作和调试目的。

```
POST   /api/v1/sessions                  # 创建新会话
GET    /api/v1/sessions/{id}             # 获取会话信息
DELETE /api/v1/sessions/{id}             # 删除会话

POST   /api/v1/sessions/{id}/turns       # 存储对话轮次
GET    /api/v1/sessions/{id}/turns       # 列出对话轮次
GET    /api/v1/sessions/{id}/turns/{tid} # 获取完整内容

GET    /api/v1/sessions/{id}/indices     # 列出索引
GET    /api/v1/sessions/{id}/search      # 搜索索引

GET    /health                           # 健康检查
GET    /metrics                          # 性能指标
```

---

## 五、数据流设计

### 5.1 写入数据流

写入数据流描述对话内容从接收到持久化的完整路径。系统采用异步处理策略，确保存储操作不会阻塞上层调用。

```
┌──────────────────────────────────────────────────────────────────────┐
│                        写入数据流完整路径                             │
└──────────────────────────────────────────────────────────────────────┘

  用户/Agent              API 网关              存储服务              索引服务
     │                      │                    │                    │
     │  1. POST /turns      │                    │                    │
     │  {content: "..."}    │                    │                    │
     │─────────────────────>│                    │                    │
     │                      │                    │                    │
     │                      │  2. 验证请求格式    │                    │
     │                      │  提取 session_id   │                    │
     │                      │                    │                    │
     │                      │  3. 异步任务入队    │                    │
     │                      │  (消息队列)         │                    │
     │                      │───────────────────>│                    │
     │                      │                    │                    │
     │  4. 202 Accepted     │                    │                    │
     │  {turn_id: "..."}    │                    │                    │
     │<─────────────────────│                    │                    │
     │                      │                    │                    │
     │                      │                    │  5. 生成摘要        │
     │                      │                    │  生成向量           │
     │                      │                    │  ─────────────────>│
     │                      │                    │                    │
     │                      │                    │                    │  6. 更新向量索引
     │                      │                    │                    │  更新倒排索引
     │                      │                    │                    │
     │                      │                    │  7. 持久化存储      │
     │                      │                    │  (SurrealDB)       │
     │                      │                    │                    │
     │                      │                    │  8. 更新索引元数据  │
     │                      │                    │  (如有必要)         │
     │                      │                    │<───────────────────│
```

**步骤详解**：

1. **请求接收**：API 网关接收对话内容请求，验证基本格式（如 Content-Type、内容长度限制等）。
2. **会话校验**：从请求头或参数中提取 session_id，验证该会话是否存在且有效。
3. **异步入队**：将处理任务推入消息队列（如 Tokio 的 MPSC 通道或 Redis Streams），立即返回 202 Accepted 响应，包含预生成的 turn_id。
4. **摘要生成**：索引服务从队列中消费任务，调用 LLM 或本地摘要模型生成 50-100 字的摘要 gist。
5. **向量化**：使用 embedding 模型将摘要编码为固定维度的向量（如 384 维）。
6. **索引更新**：将向量和元数据更新到向量索引，同时更新倒排索引的主题和标签映射。
7. **持久化**：将原始内容和元数据持久化到 SurrealDB，标记状态为 indexed。
8. **元数据更新**：更新会话的统计信息（如 total_turns）和最后活跃时间。

### 5.2 读取数据流

读取数据流描述检索请求从发起到结果返回的完整路径。为了满足 P99 < 10ms 的性能要求，读取路径采用多级缓存策略。

```
┌──────────────────────────────────────────────────────────────────────┐
│                        读取数据流完整路径                             │
└──────────────────────────────────────────────────────────────────────┘

  用户/Agent              API 网关              检索服务              存储层
     │                      │                    │                    │
     │  1. GET /search      │                    │                    │
     │  {query: "..."}      │                    │                    │
     │─────────────────────>│                    │                    │
     │                      │                    │                    │
     │                      │  2. 校验 session_id                    │
     │                      │  提取查询参数       │                    │
     │                      │                    │                    │
     │                      │  3. L1 缓存查询    │                    │
     │                      │  (本地 LRU 缓存)    │                    │
     │                      │                    │                    │
     │                      │────────────────────│                    │
     │                      │                    │                    │
     │                      │  4. 命中?          │                    │
     │                      │  ────────────────yes│─────────────────>│
     │                      │                    │  返回缓存结果       │
     │                      │                    │                    │
     │                      │<───────────────────│                    │
     │                      │                    │                    │
     │                      │  5. 索引检索        │                    │
     │                      │  (向量索引+倒排)    │                    │
     │                      │                    │                    │
     │                      │                    │  6. 获取候选列表    │
     │                      │                    │───────────────────>│
     │                      │                    │                    │
     │                      │                    │  7. 权限校验        │
     │                      │                    │  (确认所有权)       │
     │                      │                    │                    │
     │                      │  8. 返回索引列表    │                    │
     │                      │  (摘要+metadata)   │                    │
     │                      │                    │                    │
     │  9. 200 OK           │                    │                    │
     │  {indices: [...]}    │                    │                    │
     │<─────────────────────│                    │                    │
     │                      │                    │                    │
     │  10. GET /content    │                    │                    │
     │  {turn_id: "..."}    │                    │                    │
     │─────────────────────>│                    │                    │
     │                      │                    │                    │
     │                      │  11. 权限校验       │                    │
     │                      │  (强制校验)         │                    │
     │                      │                    │                    │
     │                      │  12. 获取原始内容   │                    │
     │                      │                    │───────────────────>│
     │                      │                    │                    │
     │                      │  13. 返回完整内容   │                    │
     │                      │                    │                    │
     │  14. 200 OK          │                    │                    │
     │  {content: "..."}    │                    │                    │
     │<─────────────────────│                    │                    │
```

**性能优化策略**：

1. **多级缓存**：L1 层使用进程内 LRU 缓存（热点数据），L2 层使用分布式 Redis 缓存（跨实例共享）。
2. **索引预加载**：对于高频访问的会话，定期预加载其索引到内存。
3. **向量化预计算**：查询文本在进入检索流程前预编码为向量，避免在检索循环中重复调用 embedding 模型。
4. **权限校验前置**：在执行任何存储操作前完成权限校验，避免无效的存储访问。

---

## 六、性能设计

### 6.1 延迟优化策略

针对 P99 < 10ms 的严格延迟要求，系统从架构层面进行了全面的延迟优化。

**零阻塞设计**。整个读取路径不允许存在同步阻塞调用。所有 I/O 操作（数据库查询、网络请求）都采用异步 Rust（async/await）模式实现。关键路径上的任何外部调用都必须设置超时，并在超时后返回降级结果而非阻塞等待。

```rust
// 异步查询超时控制
impl RetrievalService {
    async fn query_with_timeout(
        &self,
        query: &str,
        timeout: Duration,
    ) -> Result<Vec<IndexRecord>, Error> {
        tokio::time::timeout(timeout, async move {
            self.index_store.query(query).await
        })
        .await
        .map_err(|_| Error::QueryTimeout)
    }
}
```

**向量化执行**。利用 SIMD 指令优化向量运算。Rust 的 `rayon` 库可以方便地将迭代操作并行化，`packed_simd` 库则提供底层的 SIMD 支持。

```rust
// 向量相似度计算优化
fn cosine_similarity_optimized(a: &[f32], b: &[f32]) -> f32 {
    assert_eq!(a.len(), b.len());
    
    let dot_product: f32 = a.iter()
        .zip(b.iter())
        .map(|(&x, &y)| x * y)
        .sum();
    
    let norm_a: f32 = a.iter().map(|&x| x * x).sum::<f32>().sqrt();
    let norm_b: f32 = b.iter().map(|&x| x * x).sum::<f32>().sqrt();
    
    dot_product / (norm_a * norm_b)
}
```

**连接池优化**。数据库连接池的大小根据并发负载动态调整，保持足够的连接数以支撑峰值请求，同时避免过多空闲连接占用资源。

```rust
// 数据库连接池配置
#[derive(Clone)]
pub struct ConnectionPoolConfig {
    // 最小连接数
    min_connections: usize,
    // 最大连接数
    max_connections: usize,
    // 连接超时
    connection_timeout: Duration,
    // 空闲超时
    idle_timeout: Duration,
}

impl Default for ConnectionPoolConfig {
    fn default() -> Self {
        Self {
            min_connections: 10,
            max_connections: 100,
            connection_timeout: Duration::from_secs(30),
            idle_timeout: Duration::from_secs(600),
        }
    }
}
```

### 6.2 高并发隔离设计

系统需要支持数千个并发会话的独立检索，每个会话的数据必须严格隔离。

**会话级资源隔离**。为每个会话分配独立的资源配额，包括连接池配额、索引缓存配额、查询并发配额等。

```rust
// 会话级资源管理器
struct SessionResourceManager {
    // 会话ID -> 资源配额
    session_quotas: DashMap<String, SessionQuota>,
    
    // 全局并发控制
    global_semaphore: Semaphore,
    
    // 每个会话的并发限制
    per_session_limit: usize,
}

struct SessionQuota {
    // 当前活跃查询数
    active_queries: AtomicUsize,
    
    // 查询速率限制（每分钟）
    rate_limit: RateLimiter,
    
    // 缓存配额（字节）
    cache_quota: usize,
    
    // 索引查询超时
    query_timeout: Duration,
}

impl SessionResourceManager {
    async fn acquire_query_permit(&self, session_id: &str) -> Result<(), Error> {
        // 检查全局并发限制
        let _global_permit = self.global_semaphore.acquire().await;
        
        // 检查会话级并发限制
        let quota = self.session_quotas.get(session_id)
            .ok_or(Error::SessionNotFound)?;
        
        let current = quota.active_queries.fetch_add(1, Ordering::SeqCst);
        if current >= self.per_session_limit {
            quota.active_queries.fetch_sub(1, Ordering::SeqCst);
            return Err(Error::TooManyConcurrentQueries);
        }
        
        Ok(())
    }
    
    fn release_query_permit(&self, session_id: &str) {
        if let Some(quota) = self.session_quotas.get(session_id) {
            quota.active_queries.fetch_sub(1, Ordering::SeqCst);
        }
    }
}
```

**向量空间隔离**。每个会话拥有独立的向量索引空间，检索时仅在当前会话的向量空间内搜索。

```rust
// 向量空间隔离实现
impl VectorIndexEngine {
    pub async fn search_session(
        &self,
        session_id: &str,
        query_vector: &[f32],
        limit: u32,
    ) -> Result<Vec<SearchResult>, Error> {
        // 1. 获取会话的向量索引句柄
        let session_index = self.get_session_index(session_id).await?;
        
        // 2. 在会话索引中执行搜索（完全隔离）
        let results = session_index
            .nearest_to(query_vector)?
            .limit(limit)
            .execute()
            .await?;
        
        Ok(results)
    }
}
```

### 6.3 基准测试目标

本节定义系统在标准硬件配置下的性能基准测试目标，作为上线前性能验证和容量规划的依据。

#### 6.3.1 吞吐量基准

| 测试场景 | 目标 QPS | 备注 |
|---------|----------|------|
| 索引列表查询（纯内存操作） | ≥ 50,000 | 读取最近20条摘要 |
| 向量语义检索（P99 < 10ms） | ≥ 5,000 | 单次查询返回10条结果 |
| 全文关键词检索 | ≥ 10,000 | 基于倒排索引 |
| 混合检索（向量+全文） | ≥ 3,000 | 综合排序场景 |
| 内容获取（带权限校验） | ≥ 20,000 | 批量获取单条记录 |
| 新对话写入（异步处理） | ≥ 10,000 | 写入即返回 |

#### 6.3.2 会话容量基准

| 指标 | 目标值 | 说明 |
|------|--------|------|
| 单节点活跃会话数 | ≥ 10,000 | 每个会话有独立向量空间 |
| 单会话最大轮次数 | 1,000,000 | 理论上无限制，受存储限制 |
| 单会话向量规模 | ≤ 10,000,000 | 10M 向量约占用 4GB 存储 |
| 向量索引总规模 | ≤ 100,000,000 | 单节点 100M 向量约占用 40GB |

#### 6.3.3 延迟基准

| 百分位 | 目标延迟 | 测试场景 |
|--------|----------|----------|
| P50 | ≤ 2ms | 索引列表查询 |
| P90 | ≤ 5ms | 索引列表查询 |
| P99 | ≤ 10ms | 语义检索（不含网络传输） |
| P99.9 | ≤ 50ms | 95%请求包含完整检索链路 |

#### 6.3.4 测试方法论

性能测试应遵循以下原则：

1. **预热阶段**：在正式测试前进行 5 分钟预热，确保 JIT 编译和缓存预加载完成。
2. **持续时间**：每个场景至少运行 30 分钟，以获得稳定的性能数据。
3. **并发模型**：使用真实分布的并发请求，而非简单的均匀并发。
4. **资源监控**：同步监控系统 CPU、内存、网络、磁盘 I/O 资源使用情况。
5. **故障注入**：引入网络延迟、节点故障等 Chaos Engineering 场景，验证系统韧性。

```rust
// 性能测试框架示例
struct PerformanceBenchmark {
    // 被测服务
    service: Arc<RetrievalService>,
    
    // 请求生成器
    request_generator: RequestGenerator,
    
    // 结果收集器
    results_collector: ResultsCollector,
    
    // 负载配置
    load_config: LoadConfig,
}

impl PerformanceBenchmark {
    pub async fn run_sustained_load(&self, duration: Duration) -> BenchmarkReport {
        let start_time = Instant::now();
        let mut handles = Vec::new();
        
        // 并发请求循环
        while start_time.elapsed() < duration {
            let request = self.request_generator.next();
            let handle = self.service.execute(request);
            handles.push(handle);
            
            // 控制请求速率
            self.rate_limiter.wait().await;
        }
        
        // 等待所有请求完成
        let results = futures::future::join_all(handles).await;
        
        // 生成报告
        self.generate_report(results)
    }
}
```

### 6.4 索引更新策略

索引更新策略直接影响系统的数据一致性和写入性能。本节详细说明不同场景下的索引更新策略选择和一致性保证。

#### 6.4.1 更新策略模式

**同步更新模式**：适用于对一致性要求极高的场景。新数据写入时，必须同时完成存储和索引更新后才返回成功。

```rust
// 同步更新实现
impl IndexService {
    pub async fn store_turn_sync(&self, turn: &Turn) -> Result<(), Error> {
        // 1. 生成摘要和向量
        let gist = self.generate_gist(&turn.raw_content).await?;
        let embedding = self.embedding_model.encode(&gist).await?;
        
        // 2. 存储原始数据
        self.storage.store_turn(turn).await?;
        
        // 3. 同步更新向量索引（阻塞直到完成）
        self.vector_index.insert(&turn.id, &embedding).await?;
        
        // 4. 同步更新倒排索引
        self.inverted_index.insert(turn).await?;
        
        // 5. 所有索引更新完成后返回
        Ok(())
    }
}
```

**异步更新模式**：适用于对吞吐量要求高、可容忍短暂不一致的场景。新数据写入存储后立即返回，索引更新通过后台任务异步完成。

```rust
// 异步更新实现
impl IndexService {
    pub async fn store_turn_async(&self, turn: &Turn) -> Result<(), Error> {
        // 1. 存储原始数据（立即返回）
        self.storage.store_turn(turn).await?;
        
        // 2. 将索引更新任务推入队列
        let index_task = IndexUpdateTask {
            turn_id: turn.id.clone(),
            session_id: turn.session_id.clone(),
            raw_content: turn.raw_content.clone(),
            priority: calculate_priority(turn),
        };
        
        self.index_queue.push(index_task).await;
        
        // 3. 立即返回，索引更新在后台进行
        Ok(())
    }
}

// 后台消费者
async fn index_update_worker(mut self) {
    while let Some(task) = self.queue.pop().await {
        // 处理索引更新任务
        self.process_index_task(task).await;
    }
}
```

#### 6.4.2 一致性保证

**最终一致性窗口**：采用异步更新模式时，系统保证从数据写入到索引可检索的时间窗口不超过配置值。

```rust
struct ConsistencyConfig {
    // 最大一致性窗口（毫秒）
    max_consistency_window_ms: u64,
    
    // 强制刷新的批量大小
    batch_size_threshold: usize,
    
    // 强制刷新的时间间隔
    flush_interval_ms: u64,
}

impl Default for ConsistencyConfig {
    fn default() -> Self {
        Self {
            max_consistency_window_ms: 5000,  // 5秒窗口
            batch_size_threshold: 100,
            flush_interval_ms: 1000,          // 1秒强制刷新
        }
    }
}
```

**一致性保障机制**：

1. **写入确认**：新数据写入存储后立即返回 turn_id，数据在一致性窗口内保证可检索。
2. **后台刷新**：后台任务按配置间隔批量刷新索引，确保延迟刷新的数据最终可检索。
3. **强制刷新**：当缓冲区达到批量大小时立即触发刷新，避免数据积压。
4. **一致性检查**：定期执行存储与索引的一致性校验，修复可能的漂移。

```rust
// 一致性检查与修复
impl IndexService {
    pub async fn consistency_check(&self, session_id: &str) -> Result<ConsistencyReport, Error> {
        // 1. 获取存储中所有已索引的 turn_id
        let stored_turns = self.storage.list_indexed_turns(session_id).await?;
        
        // 2. 获取索引中的 turn_id
        let indexed_turns = self.vector_index.list_indexed(session_id).await?;
        
        // 3. 计算差集
        let missing_in_index: Vec<_> = stored_turns.iter()
            .filter(|id| !indexed_turns.contains(id))
            .collect();
        
        let missing_in_storage: Vec<_> = indexed_turns.iter()
            .filter(|id| !stored_turns.contains(id))
            .collect();
        
        // 4. 修复：重新索引缺失的数据
        for turn_id in &missing_in_index {
            if let Ok(turn) = self.storage.get_turn(turn_id).await {
                self.reindex_turn(&turn).await?;
            }
        }
        
        // 5. 清理：删除索引中多余的数据
        for turn_id in &missing_in_storage {
            self.vector_index.remove(turn_id).await?;
        }
        
        Ok(ConsistencyReport {
            missing_in_index: missing_in_index.len(),
            missing_in_storage: missing_in_storage.len(),
            fixed: missing_in_index.len(),
            cleaned: missing_in_storage.len(),
        })
    }
}
```

### 6.5 检索降级策略

在极端负载或部分组件故障情况下，系统需要具备优雅降级能力，确保核心功能可用。

#### 6.5.1 多级降级路径

```rust
enum RetrievalMode {
    Full,          // 完整模式：向量检索 + 全文检索 + 内容获取
    VectorOnly,    // 向量模式：仅向量检索，回退关键词匹配
    FtsOnly,       // 全文模式：仅关键词检索
    CachedOnly,    // 缓存模式：仅返回缓存的摘要
    Degraded,      // 降级模式：返回友好错误或空结果
}

struct RetrievalPipeline {
    // 当前检索模式
    current_mode: RetrievalMode,
    
    // 降级规则
    degradation_rules: Vec<DegradationRule>,
}
```

**降级规则配置**：

```rust
struct DegradationRule {
    // 触发条件
    condition: DegradationCondition,
    
    // 降级行动
    action: DegradationAction,
    
    // 恢复阈值
    recovery_threshold: f64,
}

enum DegradationCondition {
    LatencyExceeded(Duration),           // 延迟超时
    ErrorRateExceeded(f64),              // 错误率超标
    ServiceUnavailable(&'static str),    // 服务不可用
    QueueBacklogExceeded(usize),         // 队列积压
}

enum DegradationAction {
    DisableSemanticSearch,               // 禁用语义搜索
    DisableFullTextSearch,               // 禁用全文搜索
    DisableContentFetching,              // 禁用内容获取
    LimitResults(u32),                   // 限制返回结果数
    ReturnCacheOnly,                     // 仅返回缓存
}
```

#### 6.5.2 具体降级场景

**场景一：向量索引服务不可用**

```rust
impl RetrievalService {
    pub async fn search_with_fallback(
        &self,
        session_id: &str,
        query: &str,
        limit: u32,
    ) -> Result<Vec<IndexRecord>, Error> {
        // 尝试向量搜索
        match self.vector_search(session_id, query, limit).await {
            Ok(results) => Ok(results),
            Err(e) => {
                // 记录降级事件
                self.metrics.record_degradation("vector_search", &e);
                
                // 回退到全文搜索
                warn!("Vector search failed, falling back to FTS: {:?}", e);
                self.fts_search(session_id, query, limit).await
            }
        }
    }
}
```

**场景二：全文索引不可用**

```rust
    pub async fn search_with_fts_fallback(
        &self,
        session_id: &str,
        query: &str,
        limit: u32,
    ) -> Result<Vec<IndexRecord>, Error> {
        // 尝试混合搜索
        let hybrid_result = self.hybrid_search(session_id, query, limit).await;
        
        if hybrid_result.is_ok() {
            return hybrid_result;
        }
        
        // 尝试纯向量搜索
        let vector_result = self.vector_search(session_id, query, limit).await;
        
        if vector_result.is_ok() {
            return vector_result;
        }
        
        // 回退到时间排序的最近列表
        warn!("Both hybrid and vector search failed, falling back to recency");
        self.list_recent(session_id, limit).await
    }
```

**场景三：存储服务响应慢**

```rust
impl RetrievalService {
    pub async fn fetch_content_with_timeout(
        &self,
        session_id: &str,
        turn_id: &str,
    ) -> Result<Turn, Error> {
        // 尝试从缓存获取
        if let Some(cached) = self.cache.get(turn_id).await {
            return Ok(cached);
        }
        
        // 从存储获取，设置超时
        let content = tokio::time::timeout(
            Duration::from_millis(100),  // 100ms 超时
            self.storage.get_turn(turn_id)
        ).await;
        
        match content {
            Ok(Ok(turn)) => {
                // 更新缓存
                self.cache.set(turn_id, &turn).await;
                Ok(turn)
            }
            Ok(Err(e)) => Err(e),
            Err(_) => {
                // 超时降级：返回部分信息或错误
                Err(Error::ContentFetchTimeout)
            }
        }
    }
}
```

### 6.6 写入降级策略

写入路径同样需要完善的降级策略，确保在部分组件故障时数据不丢失。

#### 6.6.1 本地队列降级

```rust
struct WritePipeline {
    // 主队列（Redis Streams）
    primary_queue: Option<RedisStream>,
    
    // 本地队列（内存 + 磁盘持久化）
    local_queue: PersistentQueue<WriteTask>,
    
    // 重试策略
    retry_policy: RetryPolicy,
}

struct PersistentQueue<T: Serialize> {
    // 内存队列
    memory_queue: VecDeque<T>,
    
    // 磁盘持久化
    disk_store: Arc<dyn DiskStore>,
    
    // 最大内存队列长度
    max_memory_size: usize,
}

impl<T: Serialize> PersistentQueue<T> {
    pub async fn push(&mut self, task: T) -> Result<(), Error> {
        // 尝试推入内存队列
        if self.memory_queue.len() < self.max_memory_size {
            self.memory_queue.push_back(task);
            return Ok(());
        }
        
        // 内存队列满，持久化到磁盘
        self.disk_store.append(&task).await?;
        
        Ok(())
    }
    
    pub async fn pop(&mut self) -> Option<T> {
        // 先尝试从内存队列获取
        if let Some(task) = self.memory_queue.pop_front() {
            return Some(task);
        }
        
        // 从磁盘加载到内存
        self.recover_from_disk().await?;
        
        self.memory_queue.pop_front()
    }
}
```

#### 6.6.2 异步重试机制

```rust
struct RetryPolicy {
    // 最大重试次数
    max_retries: u32,
    
    // 基础退避间隔
    base_backoff_ms: u64,
    
    // 最大退避间隔
    max_backoff_ms: u64,
    
    // 指数因子
    exponential_base: f64,
}

impl RetryPolicy {
    pub fn calculate_delay(&self, attempt: u32) -> Duration {
        let backoff = self.base_backoff_ms as f64 
            * self.exponential_base.powf(attempt as f64);
        let delay_ms = backoff.min(self.max_backoff_ms as f64);
        
        // 添加随机抖动
        let jitter = (rand::random::<f64>() - 0.5) * delay_ms * 0.1;
        
        Duration::from_millis((delay_ms + jitter) as u64)
    }
}

// 重试任务执行
async fn execute_with_retry<F, T, E>(
    task: F,
    policy: &RetryPolicy,
) -> Result<T, E>
where
    F: Future<Output: Result<T, E>>,
    E: std::fmt::Display,
{
    let mut attempt = 0;
    let mut last_error: Option<E> = None;
    
    loop {
        match task.await {
            Ok(result) => return Ok(result),
            Err(e) => {
                last_error = Some(e);
                attempt += 1;
                
                if attempt >= policy.max_retries {
                    return Err(last_error.unwrap());
                }
                
                // 等待后重试
                let delay = policy.calculate_delay(attempt);
                tokio::time::sleep(delay).await;
            }
        }
    }
}
```

#### 6.6.3 降级写入流程

```rust
impl WriteService {
    pub async fn store_turn_with_fallback(
        &self,
        turn: &Turn,
    ) -> Result<WriteResult, WriteError> {
        // 尝试主路径：写入存储 + 索引队列
        let primary_result = self.write_via_primary(turn).await;
        
        if primary_result.is_ok() {
            return primary_result;
        }
        
        // 主路径失败，尝试本地队列
        warn!("Primary write path failed, falling back to local queue");
        
        // 保存到本地队列
        let task = WriteTask {
            turn: turn.clone(),
            timestamp: now(),
            retry_count: 0,
        };
        
        self.local_queue.push(task).await.map_err(|e| {
            WriteError::QueueFull(format!("Failed to enqueue: {:?}", e))
        })?;
        
        // 标记为已接受，异步处理
        Ok(WriteResult {
            status: WriteStatus::Queued,
            turn_id: turn.id.clone(),
            message: "写入已加入队列，将在服务恢复后处理".to_string(),
        })
    }
}

// 队列恢复任务
async fn queue_recovery_worker(mut self) {
    let mut interval = tokio::time::interval(Duration::from_secs(30));
    
    loop {
        interval.tick().await;
        
        // 检查主路径是否恢复
        if self.is_primary_available().await {
            // 逐个处理本地队列中的任务
            while let Some(task) = self.local_queue.pop().await {
                if let Err(e) = self.write_via_primary(&task.turn).await {
                    // 处理失败，增加重试计数
                    task.retry_count += 1;
                    
                    if task.retry_count < MAX_RETRY {
                        self.local_queue.push(task).await;
                    } else {
                        // 超过最大重试次数，移到死信队列
                        self.dead_letter_queue.push(task).await;
                    }
                }
            }
        }
    }
}
```

### 6.7 性能监控与告警

系统内置完善的性能监控体系，实时追踪关键性能指标。

```rust
// 性能指标收集
struct MetricsCollector {
    // 检索延迟直方图
    retrieval_latency: Histogram,
    
    // 并发请求计数
    concurrent_requests: Gauge,
    
    // 缓存命中率
    cache_hit_rate: Gauge,
    
    // 错误率
    error_rate: Counter,
}

impl MetricsCollector {
    pub async fn record_retrieval(&self, session_id: &str, latency: Duration) {
        self.retrieval_latency.observe(latency.as_secs_f64());
        
        // 检查 P99 延迟
        let p99 = self.retrieval_latency.percentile(99.0);
        if p99 > 0.01 {  // 10ms
            alert!(level: Warning, "P99 latency exceeded 10ms: {}s", p99);
        }
    }
}
```

---

## 七、安全性设计

### 7.1 会话隔离机制

会话隔离是 Hippos 的核心安全特性，需要在多个层面得到保障。

**存储层隔离**。每个会话的数据存储在独立的 SurrealDB Namespace 中，跨 Namespace 的数据访问需要显式的权限配置。

```rust
// SurrealDB Namespace 隔离
impl StorageBackend {
    async fn create_session_namespace(&self, session_id: &str) -> Result<(), Error> {
        // 创建 Namespace
        self.db.query(&format!("DEFINE NAMESPACE {}", session_id)).await?;
        
        // 初始化数据库
        self.db.use_ns(session_id).use_db("session_data").await?;
        
        // 创建表结构
        self.db.query("DEFINE TABLE turn SCHEMAFULL").await?;
        self.db.query("DEFINE FIELD id ON turn TYPE string").await?;
        self.db.query("DEFINE FIELD session_id ON turn TYPE string").await?;
        self.db.query("DEFINE INDEX idx_session_id ON turn FIELDS session_id").await?;
        
        Ok(())
    }
    
    async fn query_with_isolation<T>(
        &self,
        session_id: &str,
        query: &str,
    ) -> Result<T, Error> 
    where
        T: DeserializeOwned,
    {
        // 确保查询在正确的 Namespace 中执行
        self.db.use_ns(session_id).use_db("session_data").await?;
        
        // 执行查询
        self.db.query(query).await?.take(0)
    }
}
```

**检索层隔离**。每次检索操作都必须携带有效的 session_id，且检索结果仅包含该 session 拥有的数据。

```rust
// 检索隔离强制执行
impl RetrievalService {
    async fn search_with_enforced_isolation(
        &self,
        session_id: &str,
        query: &str,
    ) -> Result<Vec<IndexRecord>, Error> {
        // 1. 验证 session_id 格式（防止注入攻击）
        validate_session_id(session_id)?;
        
        // 2. 验证会话存在且有效
        let session = self.session_store.get(session_id).await?
            .ok_or(Error::SessionNotFound)?;
        
        if session.status == SessionStatus::Deleted {
            return Err(Error::SessionDeleted);
        }
        
        // 3. 在索引查询中强制添加 session_id 过滤
        let isolated_query = format!(
            "SELECT * FROM index_record WHERE session_id = '{}' AND ({})",
            session_id, query
        );
        
        // 4. 执行隔离查询
        let results = self.index_store.query(&isolated_query).await?;
        
        // 5. 防御性过滤（确保结果确实属于该会话）
        let valid_results: Vec<IndexRecord> = results
            .into_iter()
            .filter(|r| r.session_id == session_id)
            .collect();
        
        Ok(valid_results)
    }
}
```

### 7.2 权限校验体系

系统采用细粒度的权限校验机制，确保每次数据访问都经过严格验证。

**所有权校验**。核心校验逻辑是验证请求者是否拥有被访问数据的所属权。

```rust
// 所有权校验
async fn validate_ownership(
    &self,
    session_id: &str,
    turn_id: &str,
) -> Result<Turn, Error> {
    // 1. 提取 turn_id 中的 session_id
    let turn_session_id = extract_session_from_turn_id(turn_id)?;
    
    // 2. 验证匹配
    if turn_session_id != session_id {
        // 记录安全事件
        self.security_audit.log(SecurityEvent {
            event_type: EventType::UnauthorizedAccess,
            source_session: session_id,
            target_turn: turn_id,
            timestamp: now(),
        });
        
        return Err(Error::OwnershipValidationFailed);
    }
    
    // 3. 从存储加载并再次验证
    let turn = self.storage.get_turn(turn_id).await?
        .ok_or(Error::TurnNotFound)?;
    
    if turn.session_id != session_id {
        return Err(Error::OwnershipValidationFailed);
    }
    
    Ok(turn)
}
```

**访问控制列表**。支持更复杂的访问控制场景，如会话共享、委托访问等。

```rust
// 访问控制列表
struct AccessControlList {
    // 资源类型
    resource_type: ResourceType,
    
    // 资源标识
    resource_id: String,
    
    // 允许的访问者列表
    allowed_subjects: Vec<Subject>,
    
    // 权限列表
    permissions: Vec<Permission>,
}

enum Subject {
    User(String),
    Session(String),
    Role(String),
}

enum Permission {
    Read,
    Write,
    Delete,
    Share,
}

impl AccessControlService {
    async fn check_access(
        &self,
        subject: &Subject,
        resource: &AccessControlList,
    ) -> Result<bool, Error> {
        // 检查 subject 是否在 allowed_subjects 中
        let is_allowed = resource.allowed_subjects
            .contains(subject);
        
        if !is_allowed {
            // 记录拒绝事件
            self.audit_log.log(AccessDeniedEvent {
                subject,
                resource: &resource.resource_id,
                timestamp: now(),
            });
        }
        
        Ok(is_allowed)
    }
}
```

### 7.3 数据安全

**传输加密**。所有 API 通信强制使用 TLS 1.3 加密，确保传输过程中的数据安全。

**存储加密**。敏感数据（如对话内容）在存储层进行加密保护。支持两种加密模式：透明加密（TDE）和应用层加密。

```rust
// 存储加密实现
struct EncryptedStorage {
    // 加密引擎
    cipher: Aes256Gcm,
    
    // 密钥管理
    key_manager: KeyManager,
    
    // 底层存储
    inner: Surreal<Ws>,
}

impl EncryptedStorage {
    async fn store_turn(&self, turn: &Turn) -> Result<(), Error> {
        // 1. 序列化
        let raw_data = serde_json::to_vec(&turn)?;
        
        // 2. 加密
        let encrypted = self.cipher.encrypt(
            self.key_manager.get_data_key().await?,
            raw_data,
        )?;
        
        // 3. 存储密文
        self.inner.update(("turn", &turn.id))
            .content(EncryptedTurn {
                ciphertext: encrypted,
                key_version: self.key_manager.current_version(),
            })
            .await?;
        
        Ok(())
    }
    
    async fn load_turn(&self, turn_id: &str) -> Result<Turn, Error> {
        // 1. 读取密文
        let encrypted: EncryptedTurn = self.inner.select(("turn", turn_id)).await?;
        
        // 2. 解密
        let key = self.key_manager.get_key(encrypted.key_version).await?;
        let raw_data = self.cipher.decrypt(key, &encrypted.ciphertext)?;
        
        // 3. 反序列化
        let turn = serde_json::from_slice(&raw_data)?;
        
        Ok(turn)
    }
}
```

**审计日志**。所有安全相关的操作都被记录到审计日志中，包括登录尝试、权限变更、数据访问等。

```rust
// 审计日志
struct AuditLogger {
    // 日志存储
    storage: Arc<dyn LogStorage>,
    
    // 敏感操作过滤器
    sensitive_ops: Vec<&'static str>,
}

impl AuditLogger {
    pub async fn log(&self, event: &AuditEvent) {
        // 标记敏感事件
        if self.sensitive_ops.contains(&event.operation) {
            let sensitive_event = SensitiveEvent {
                event,
                risk_level: RiskLevel::from(event),
                requires_review: true,
            };
            
            // 异步存储
            self.storage.store(&sensitive_event).await;
            
            // 高风险事件实时告警
            if sensitive_event.risk_level == RiskLevel::Critical {
                alert!(level: Critical, "{:?}", sensitive_event);
            }
        }
    }
}
```

### 7.4 请求频率限制

为防止恶意请求和服务滥用，系统实施多层次的请求频率限制策略。

#### 7.4.1 全局限流

```rust
// 全局限流器
struct GlobalRateLimiter {
    // Redis 分布式锁
    redis: Arc<RedisClient>,
    
    // 滑动窗口配置
    window_size: Duration,
    max_requests: u64,
    
    // Lua 脚本（原子操作）
    lua_script: String,
}

impl GlobalRateLimiter {
    pub async fn check_global_limit(&self, client_ip: &str) -> Result<(), RateLimitError> {
        let key = format!("rate_limit:global:{}", client_ip);
        
        // 使用 Redis 原子操作实现滑动窗口
        let result: Result<bool, RedisError> = self.redis
            .eval::<bool>(
                &self.lua_script,
                vec![key],
                vec![self.window_size.as_secs(), self.max_requests]
            )
            .await;
        
        match result {
            Ok(true) => Ok(()),  // 在限制内
            Ok(false) => Err(RateLimitError::GlobalLimitExceeded),
            Err(e) => Err(RateLimitError::RedisUnavailable(e)),
        }
    }
}
```

#### 7.4.2 会话级限流

```rust
// 会话级限流配置
struct SessionRateLimitConfig {
    // 每分钟最大请求数
    requests_per_minute: u64,
    
    // 每小时最大写入数
    writes_per_hour: u64,
    
    // 并发查询限制
    max_concurrent_queries: usize,
    
    // 突发请求配额
    burst_capacity: u64,
}

// 会话限流器
struct SessionRateLimiter {
    session_id: String,
    config: SessionRateLimitConfig,
    
    // 令牌桶
    token_bucket: TokenBucket,
    
    // 并发控制
    semaphore: Semaphore,
}

impl SessionRateLimiter {
    pub async fn check_read_limit(&self) -> Result<(), RateLimitError> {
        // 检查令牌桶
        if !self.token_bucket.try_consume(1) {
            return Err(RateLimitError::TooManyRequests);
        }
        
        Ok(())
    }
    
    pub async fn acquire_write_permit(&self) -> Result<Permit, RateLimitError> {
        // 获取写入许可
        let permit = self.semaphore.try_acquire_owned()
            .map_err(|_| RateLimitError::WriteQuotaExceeded)?;
        
        Ok(permit)
    }
}
```

#### 7.4.3 限流响应策略

```rust
// 限流响应
struct RateLimitResponse {
    // 允许的最大请求数
    limit: u64,
    
    // 剩余请求数
    remaining: u64,
    
    // 重置时间（Unix 时间戳）
    reset_at: u64,
    
    // Retry-After 时间（秒）
    retry_after: u64,
}

impl RateLimitResponse {
    pub fn to_headers(&self) -> HashMap<String, String> {
        let mut headers = HashMap::new();
        headers.insert("X-RateLimit-Limit".to_string(), self.limit.to_string());
        headers.insert("X-RateLimit-Remaining".to_string(), self.remaining.to_string());
        headers.insert("X-RateLimit-Reset".to_string(), self.reset_at.to_string());
        headers.insert("Retry-After".to_string(), self.retry_after.to_string());
        headers
    }
}

// 限流中间件
async fn rate_limit_middleware<B>(req: Request<B>, next: Next<B>) -> Response {
    let client_ip = extract_client_ip(&req);
    
    // 检查全局限流
    if let Err(e) = GLOBAL_LIMITER.check_global_limit(&client_ip).await {
        return create_rate_limit_response(e);
    }
    
    // 获取会话ID
    let session_id = extract_session_id(&req).unwrap_or_default();
    
    // 检查会话限流
    if !session_id.is_empty() {
        if let Some(limiter) = SESSION_LIMITERS.get(&session_id) {
            if let Err(e) = limiter.check_read_limit().await {
                return create_rate_limit_response(e);
            }
        }
    }
    
    // 继续处理请求
    next.run(req).await
}
```

### 7.5 DDoS 防护机制

系统需要具备抵御分布式拒绝服务攻击的能力，确保在遭受攻击时仍能正常服务合法请求。

#### 7.5.1 流量识别与过滤

```rust
// DDoS 防护配置
struct DDoSProtectionConfig {
    // 正常请求阈值
    normal_threshold: u64,
    
    // 警告请求阈值
    warning_threshold: u64,
    
    // 攻击检测阈值
    attack_threshold: u64,
    
    // 封禁时间（秒）
    ban_duration: Duration,
    
    // 白名单
    whitelist: Vec<String>,
}

struct DDoSProtection {
    config: DDoSProtectionConfig,
    
    // IP 访问频率追踪
    ip_tracker: DashMap<String, IpAccessTracker>,
    
    // 被封禁的 IP
    banned_ips: RwLock<HashSet<String>>,
    
    // 威胁情报源
    threat_intel: Arc<dyn ThreatIntelligence>,
}

struct IpAccessTracker {
    request_count: AtomicU64,
    last_access: AtomicU64,
    threat_score: AtomicU64,
}
```

#### 7.5.2 攻击检测与响应

```rust
impl DDoSProtection {
    pub async fn analyze_and_protect(&self, client_ip: &str, request: &Request) -> ProtectionAction {
        // 1. 检查是否在白名单
        if self.config.whitelist.contains(&client_ip) {
            return ProtectionAction::Allow;
        }
        
        // 2. 检查是否已被封禁
        if self.is_banned(client_ip) {
            return ProtectionAction::Reject;
        }
        
        // 3. 获取或创建追踪器
        let tracker = self.ip_tracker.entry(client_ip.to_string())
            .or_insert(IpAccessTracker::new());
        
        // 4. 更新访问统计
        tracker.record_access();
        
        // 5. 检查威胁情报
        if self.threat_intel.is_malicious(client_ip).await {
            self.ban_ip(client_ip);
            return ProtectionAction::Reject;
        }
        
        // 6. 计算威胁分数
        let threat_score = self.calculate_threat_score(tracker, request);
        
        // 7. 根据威胁分数采取行动
        match threat_score {
            s if s < self.config.normal_threshold => ProtectionAction::Allow,
            s if s < self.config.warning_threshold => ProtectionAction::Log,
            s if s < self.config.attack_threshold => {
                // 触发验证码或人机验证
                ProtectionAction::Challenge
            }
            _ => {
                // 封禁 IP
                self.ban_ip(client_ip);
                ProtectionAction::Reject
            }
        }
    }
    
    fn calculate_threat_score(&self, tracker: &IpAccessTracker, request: &Request) -> u64 {
        let mut score = 0;
        
        // 请求频率评分
        let request_rate = tracker.request_count.load(Ordering::Relaxed);
        if request_rate > self.config.warning_threshold {
            score += 50;
        }
        
        // 请求模式评分
        if self.has_unusual_pattern(request) {
            score += 30;
        }
        
        // User-Agent 评分
        if self.is_suspicious_user_agent(request) {
            score += 20;
        }
        
        score
    }
}
```

#### 7.5.3 流量清洗

```rust
// 流量清洗服务
struct TrafficCleaningService {
    // 清洗规则
    cleaning_rules: Vec<CleaningRule>,
    
    // 验证码服务
    captcha_service: Arc<dyn CaptchaService>,
    
    // 行为分析
    behavior_analyzer: BehaviorAnalyzer,
}

enum CleaningRule {
    // JS 挑战
    JavaScriptChallenge {
        payload: String,
        cookie_name: String,
    },
    
    // 验证码挑战
    CaptchaChallenge {
        provider: CaptchaProvider,
        difficulty: Difficulty,
    },
    
    // 重定向到验证页面
    RedirectToVerification {
        url: String,
        token_ttl: Duration,
    },
}

// 流量清洗中间件
async fn traffic_cleaning_middleware<B>(req: Request<B>, next: Next<B>) -> Response {
    let client_ip = extract_client_ip(&req);
    
    // 初步分析
    let action = DDOS_PROTECTION.analyze_and_protect(&client_ip, &req).await;
    
    match action {
        ProtectionAction::Allow => next.run(req).await,
        ProtectionAction::Challenge => {
            // 返回挑战页面
            create_challenge_response(&DDOS_PROTECTION.config)
        }
        ProtectionAction::Reject => {
            // 返回 403 或 429
            create_rejection_response()
        }
        ProtectionAction::Log => {
            // 记录日志但允许通过
            log_request(&req);
            next.run(req).await
        }
    }
}
```

### 7.6 密钥管理方案

系统采用专业的密钥管理方案，确保加密密钥的安全存储、轮换和访问控制。

#### 7.6.1 密钥分层架构

```rust
// 密钥分层结构
struct KeyHierarchy {
    // 根密钥（Master Key）：最高级别密钥，存储在硬件安全模块（HSM）
    root_key: Arc<dyn HsmKey>,
    
    // 密钥加密密钥（KEK）：用于加密数据密钥
    kek_version: KeyVersion,
    
    // 数据加密密钥（DEK）：用于加密实际数据
    data_keys: KeyCache<EncryptedDataKey>,
}

// 加密数据密钥结构
struct EncryptedDataKey {
    // 密钥标识
    key_id: String,
    
    // 使用 KEK 加密后的 DEK
    encrypted_key: Vec<u8>,
    
    // 密钥版本
    version: u64,
    
    // 创建时间
    created_at: SystemTime,
    
    // 过期时间（可选）
    expires_at: Option<SystemTime>,
}
```

#### 7.6.2 KMS 集成

```rust
// KMS 配置
struct KeyManagementConfig {
    // KMS 提供商
    provider: KeyProvider,
    
    // AWS KMS 配置
    aws_kms_config: Option<AwsKmsConfig>,
    
    // GCP KMS 配置
    gcp_kms_config: Option<GcpKmsConfig>,
    
    // 密钥轮换周期
    rotation_period: Duration,
    
    // 紧急轮换触发条件
    emergency_rotation_triggers: Vec<RotationTrigger>,
}

enum KeyProvider {
    AwsKms {
        region: String,
        key_arn: String,
    },
    GcpKms {
        project: String,
        location: String,
        key_ring: String,
        key_name: String,
    },
    AzureKeyVault {
        vault_name: String,
        key_name: String,
    },
    LocalHsm {
        // 用于开发测试
        hsm_address: String,
    },
}

// KMS 客户端
struct KmsClient {
    config: KeyManagementConfig,
    
    // 实际的 KMS 客户端
    inner_client: Box<dyn KmsProvider>,
    
    // 本地密钥缓存
    local_cache: RwLock<HashMap<String, CachedKey>>,
    
    // 密钥轮换器
    rotator: KeyRotator,
}

impl KmsClient {
    // 获取数据加密密钥
    pub async fn get_data_key(&self, key_id: &str) -> Result<DataKey, KeyError> {
        // 1. 检查本地缓存
        if let Some(cached) = self.local_cache.read().unwrap().get(key_id) {
            if !cached.is_expired() {
                return Ok(cached.key.clone());
            }
        }
        
        // 2. 从 KMS 获取新密钥
        let encrypted_key = self.inner_client
            .generate_data_key(key_id, 32)  // 32字节 = 256位
            .await?;
        
        // 3. 解密明文密钥
        let plaintext_key = self.inner_client
            .decrypt(&encrypted_key.ciphertext)
            .await?;
        
        // 4. 缓存加密后的密钥
        let cached = CachedKey {
            key: DataKey {
                id: key_id.to_string(),
                material: plaintext_key.clone(),
            },
            encrypted_copy: encrypted_key,
            cached_at: now(),
            expires_at: now() + self.config.rotation_period,
        };
        
        self.local_cache.write().unwrap().insert(key_id.to_string(), cached);
        
        Ok(DataKey {
            id: key_id.to_string(),
            material: plaintext_key,
        })
    }
    
    // 密钥轮换
    pub async fn rotate_keys(&self) -> Result<(), KeyError> {
        // 1. 生成新的数据密钥
        let new_key = self.inner_client
            .generate_data_key("main-data-key", 32)
            .await?;
        
        // 2. 重新加密所有现有数据（渐进式）
        self.re_encrypt_data(&new_key).await?;
        
        // 3. 更新 KMS 中的密钥版本
        self.inner_client.update_key_version("main-data-key").await?;
        
        // 4. 使旧密钥缓存失效
        self.local_cache.write().unwrap().clear();
        
        // 5. 记录审计日志
        self.audit_log.log(KeyRotationEvent {
            timestamp: now(),
            key_id: "main-data-key",
            new_version: new_key.version,
        });
        
        Ok(())
    }
}
```

#### 7.6.3 密钥使用审计

```rust
// 密钥使用审计
struct KeyAuditLogger {
    // 审计日志存储
    audit_storage: Arc<dyn AuditStorage>,
    
    // 敏感密钥列表
    sensitive_keys: Vec<&'static str>,
}

impl KeyAuditLogger {
    pub async fn log_key_usage(&self, event: KeyUsageEvent) {
        // 标记敏感密钥的使用
        if self.sensitive_keys.contains(&event.key_id.as_str()) {
            let audit_record = KeyAuditRecord {
                event_type: event.operation,
                key_id: event.key_id,
                request_id: event.request_id,
                client_ip: event.client_ip,
                user_id: event.user_id,
                timestamp: now(),
                outcome: event.outcome,
            };
            
            // 异步存储审计记录
            self.audit_storage.store(&audit_record).await;
            
            // 敏感密钥使用告警
            if event.outcome == KeyOutcome::Denied {
                alert!(level: Critical, "Key access denied: {:?}", audit_record);
            }
        }
    }
}
```

---

## 八、监控与运维

### 8.1 监控指标体系

完善的监控体系是保障系统稳定运行的关键。Hippos 建立多层次的监控指标体系，覆盖系统健康、性能表现、业务运营等维度。

#### 8.1.1 核心性能指标

| 指标名称 | 类型 | 采集粒度 | 告警阈值 | 说明 |
|---------|------|----------|----------|------|
| retrieval_latency_p50 | Histogram | 1分钟 | ≤ 5ms | 检索延迟 P50 |
| retrieval_latency_p99 | Histogram | 1分钟 | ≤ 10ms | 检索延迟 P99 |
| retrieval_latency_p999 | Histogram | 1分钟 | ≤ 50ms | 检索延迟 P99.9 |
| vector_index_hit_rate | Gauge | 1分钟 | < 95% | 向量索引命中率 |
| cache_hit_rate | Gauge | 1分钟 | < 80% | 缓存命中率 |
| dehydration_latency | Histogram | 1分钟 | ≤ 100ms | 脱水处理延迟 |
| index_update_latency | Histogram | 1分钟 | ≤ 500ms | 索引更新延迟 |

#### 8.1.2 会话运营指标

| 指标名称 | 类型 | 采集粒度 | 告警阈值 | 说明 |
|---------|------|----------|----------|------|
| active_sessions | Gauge | 1分钟 | > 容量上限 | 活跃会话数 |
| session_creation_rate | Counter | 1分钟 | 异常波动 | 会话创建速率 |
| session_deletion_rate | Counter | 1分钟 | 异常增长 | 会话删除速率 |
| turns_per_session_avg | Gauge | 5分钟 | 偏离基线 | 平均每会话轮次 |
| session_age_avg | Gauge | 5分钟 | - | 平均会话寿命 |
| concurrent_queries | Gauge | 10秒 | > 限制 | 并发查询数 |

#### 8.1.3 存储层指标

| 指标名称 | 类型 | 采集粒度 | 告警阈值 | 说明 |
|---------|------|----------|----------|------|
| storage_used_bytes | Gauge | 5分钟 | > 80% 容量 | 已用存储空间 |
| vector_index_size | Gauge | 5分钟 | 接近上限 | 向量索引规模 |
| memory_usage_ratio | Gauge | 1分钟 | > 85% | 内存使用率 |
| disk_io_utilization | Gauge | 1分钟 | > 80% | 磁盘 IO 利用率 |
| db_connection_pool_usage | Gauge | 1分钟 | > 90% | 数据库连接池使用率 |
| replication_lag | Gauge | 1分钟 | > 5s | 主从复制延迟 |

#### 8.1.4 安全监控指标

| 指标名称 | 类型 | 采集粒度 | 告警阈值 | 说明 |
|---------|------|----------|----------|------|
| authentication_failures | Counter | 1分钟 | 异常增长 | 认证失败次数 |
| authorization_denials | Counter | 1分钟 | > 阈值 | 授权拒绝次数 |
| rate_limit_exceeded | Counter | 1分钟 | > 阈值 | 限流触发次数 |
| suspicious_requests | Counter | 1分钟 | > 0 | 可疑请求数 |
| banned_ips_count | Gauge | 5分钟 | - | 被封禁 IP 数 |
| encryption_failures | Counter | 1分钟 | > 0 | 加密失败次数 |

#### 8.1.5 指标采集实现

```rust
// 指标采集器
struct MetricsCollector {
    // Prometheus 注册表
    registry: Registry,
    
    // 检索延迟直方图
    retrieval_latency: HistogramVec,
    
    // 缓存命中率
    cache_hit_rate: GaugeVec,
    
    // 会话计数器
    session_counter: IntCounterVec,
    
    // 向量索引指标
    vector_index_size: IntGaugeVec,
}

impl MetricsCollector {
    pub fn new() -> Self {
        let registry = Registry::new();
        
        // 初始化检索延迟直方图
        let retrieval_latency = HistogramVec::new(
            HistogramOpts::new(
                "hippos_retrieval_latency_seconds",
                "Retrieval operation latency in seconds"
            ),
            &["operation_type", "session_id"]
        );
        registry.register(Box::new(retrieval_latency.clone())).unwrap();
        
        // 初始化缓存命中率
        let cache_hit_rate = GaugeVec::new(
            GaugeOpts::new(
                "hippos_cache_hit_rate",
                "Cache hit rate percentage"
            ),
            &["cache_type"]
        );
        registry.register(Box::new(cache_hit_rate.clone())).unwrap();
        
        Self {
            registry,
            retrieval_latency,
            cache_hit_rate,
            session_counter: IntCounterVec::new(
                CounterOpts::new(
                    "hippos_session_operations_total",
                    "Total session operations"
                ),
                &["operation"]
            ),
            vector_index_size: IntGaugeVec::new(
                GaugeOpts::new(
                    "hippos_vector_index_size",
                    "Vector index size by session"
                ),
                &["session_id"]
            ),
        }
    }
    
    // 记录检索延迟
    pub fn record_retrieval(&self, operation: &str, session_id: &str, latency: Duration) {
        self.retrieval_latency
            .with_label_values(&[operation, session_id])
            .observe(latency.as_secs_f64());
    }
    
    // 更新缓存命中率
    pub fn update_cache_hit_rate(&self, cache_type: &str, hits: u64, misses: u64) {
        let total = hits + misses;
        if total > 0 {
            let rate = (hits as f64 / total as f64) * 100.0;
            self.cache_hit_rate
                .with_label_values(&[cache_type])
                .set(rate);
        }
    }
}
```

### 8.2 日志收集与分析

#### 8.2.1 日志级别与格式

```rust
// 日志级别定义
enum LogLevel {
    Error,   // 错误：需要立即处理
    Warn,    // 警告：可能影响功能
    Info,    // 信息：正常操作记录
    Debug,   // 调试：开发调试用
    Trace,   // 跟踪：详细执行路径
}

// 结构化日志格式
struct StructuredLog {
    // 时间戳（ISO 8601）
    timestamp: String,
    
    // 日志级别
    level: LogLevel,
    
    // 服务名称
    service: String,
    
    // 主机名
    hostname: String,
    
    // 请求 ID（用于链路追踪）
    request_id: String,
    
    // 会话 ID
    session_id: Option<String>,
    
    // 用户 ID
    user_id: Option<String>,
    
    // 组件名称
    component: String,
    
    // 消息模板
    message_template: String,
    
    // 结构化参数
    params: HashMap<String, Value>,
    
    // 异常堆栈（如果有）
    stack_trace: Option<String>,
}
```

#### 8.2.2 日志收集架构

```
┌─────────────────────────────────────────────────────────────────────┐
│                        日志收集架构                                  │
└─────────────────────────────────────────────────────────────────────┘

  Hippos 实例                      日志收集层                      分析层
      │                                  │                             │
      │  1. 应用日志输出                  │                             │
      │  (JSON 格式)                     │                             │
      │─────────────────────────────────>│                             │
      │                                  │                             │
      │  2. Filebeat/Fluentd 采集         │                             │
      │  (本地文件)                      │                             │
      │─────────────────────────────────>│                             │
      │                                  │  3. 日志聚合与处理           │
      │                                  │  (格式化、过滤、富化)        │
      │                                  │────────────────────────────>│
      │                                  │                             │
      │                                  │  4. 发送到存储               │
      │                                  │  (Elasticsearch/Loki)       │
      │                                  │────────────────────────────>│
      │                                  │                             │
      │                                  │                             │  5. 可视化查询
      │                                  │                             │<────────────────
```

#### 8.2.3 ELK 集成配置

```yaml
# Filebeat 配置示例
filebeat.inputs:
  - type: log
    enabled: true
    paths:
      - /var/log/hippos/*.log
    json:
      keys_under_root: true
      overwrite_keys: true
      add_error_key: true
    multiline:
      pattern: '^\d{4}-\d{2}-\d{2}'
      negate: true
      match: after

processors:
  - add_host_metadata:
      when.not.contains.tags: forwarded
  - add_cloud_metadata: ~
  - add_docker_metadata: ~

output.elasticsearch:
  hosts: ["elasticsearch:9200"]
  index: "hippos-logs-%{[fields.log_type]}"
  bulk_max_size: 2048

setup.template:
  name: "hippos"
  pattern: "hippos-*"
```

#### 8.2.4 Loki + Grafana 集成配置

```yaml
# Promtail 配置示例
server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
  - job_name: hippos
    static_configs:
      - targets:
          - localhost
        labels:
          job: hippos
          __path__: /var/log/hippos/*.log
    pipeline_stages:
      - json:
          expressions:
            timestamp: timestamp
            level: level
            message: message
      - regex:
          expression: 'request_id="(?P<request_id>[^"]+)"'
      - labels:
          level:
          service:
      - timestamp:
          source: timestamp
          format: RFC3339Nano
```

### 8.3 告警规则设计

#### 8.3.1 告警级别定义

| 级别 | 名称 | 说明 | 响应时间 |
|------|------|------|----------|
| P1 | Critical | 系统不可用或数据丢失风险 | 立即响应 |
| P2 | High | 核心功能受损，影响用户体验 | 15分钟内 |
| P3 | Medium | 非核心功能异常，需要关注 | 1小时内 |
| P4 | Low | 潜在问题或性能下降 | 工作时间内 |

#### 8.3.2 核心告警规则

```yaml
# Prometheus AlertManager 告警规则示例
groups:
  - name: hippos-critical
    rules:
      # P1: 服务不可用
      - alert: ServiceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Hippos 服务不可用"
          description: "服务 {{ $labels.instance }} 已经宕机超过 1 分钟"
      
      # P1: 检索延迟过高
      - alert: RetrievalLatencyHigh
        expr: |
          histogram_quantile(0.99, rate(hippos_retrieval_latency_seconds_bucket[5m])) > 0.01
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "检索 P99 延迟超过 10ms"
          description: "当前 P99 延迟: {{ $value | humanizeDuration }}"
      
      # P1: 向量索引不可用
      - alert: VectorIndexUnavailable
        expr: hippos_vector_index_health == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "向量索引服务不可用"
      
      # P1: 存储写入失败率
      - alert: StorageWriteFailureHigh
        expr: |
          rate(hippos_storage_write_errors_total[5m]) /
          rate(hippos_storage_writes_total[5m]) > 0.01
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "存储写入失败率超过 1%"
  
  - name: hippos-warning
    rules:
      # P2: 缓存命中率低
      - alert: CacheHitRateLow
        expr: hippos_cache_hit_rate < 0.8
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "缓存命中率低于 80%"
          description: "当前缓存命中率: {{ $value | humanizePercentage }}"
      
      # P2: 并发连接数高
      - alert: HighConnectionCount
        expr: hippos_active_connections > 8000
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "并发连接数接近上限"
          description: "当前连接数: {{ $value }}"
      
      # P2: 内存使用率高
      - alert: MemoryUsageHigh
        expr: (1 - hippos_memory_available_bytes / hippos_memory_total_bytes) > 0.85
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "内存使用率超过 85%"
      
      # P3: 会话创建失败
      - alert: SessionCreationFailures
        expr: |
          rate(hippos_session_creation_errors_total[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "会话创建失败率异常"
      
      # P3: 限流触发频繁
      - alert: RateLimitTriggers
        expr: |
          rate(hippos_rate_limit_exceeded_total[5m]) > 10
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "请求限流触发频繁"
          description: "触发次数: {{ $value }}/s"
```

#### 8.3.3 告警通知渠道

```yaml
# AlertManager 通知配置
global:
  resolve_timeout: 5m

route:
  group_by: ['alertname', 'severity']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  receiver: 'default-receiver'
  routes:
    - match:
        severity: critical
      receiver: 'critical-receiver'
      continue: true
    - match:
        severity: warning
      receiver: 'warning-receiver'

receivers:
  - name: 'default-receiver'
    webhook_configs:
      - url: 'http://alertmanager-webhook:5000/receive'
        send_resolved: true
  
  - name: 'critical-receiver'
    webhook_configs:
      - url: 'http://pagerduty-webhook/integrations/generic/20004949'
        send_resolved: true
    email_configs:
      - to: 'ops-team@company.com'
        send_resolved: true
  
  - name: 'warning-receiver'
    webhook_configs:
      - url: 'http://slack-webhook:5000/alerts'
        send_resolved: true
    email_configs:
      - to: 'dev-team@company.com'
        send_resolved: true
```

### 8.4 运维仪表盘

#### 8.4.1 Grafana 仪表盘配置

```json
{
  "dashboard": {
    "title": "Hippos Overview",
    "tags": ["hippos", "overview"],
    "timezone": "browser",
    "refresh": "30s",
    
    "panels": [
      {
        "title": "检索延迟分布",
        "type": "timeseries",
        "gridPos": {"x": 0, "y": 0, "w": 12, "h": 8},
        "targets": [
          {
            "expr": "histogram_quantile(0.50, rate(hippos_retrieval_latency_seconds_bucket[5m]))",
            "legendFormat": "P50"
          },
          {
            "expr": "histogram_quantile(0.99, rate(hippos_retrieval_latency_seconds_bucket[5m]))",
            "legendFormat": "P99"
          }
        ]
      },
      {
        "title": "缓存命中率",
        "type": "gauge",
        "gridPos": {"x": 12, "y": 0, "w": 12, "h": 8},
        "targets": [
          {
            "expr": "avg(hippos_cache_hit_rate)",
            "refId": "A"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "percent",
            "min": 0,
            "max": 100,
            "thresholds": {
              "mode": "absolute",
              "steps": [
                {"value": 0, "color": "red"},
                {"value": 80, "color": "yellow"},
                {"value": 95, "color": "green"}
              ]
            }
          }
        }
      },
      {
        "title": "活跃会话数",
        "type": "timeseries",
        "gridPos": {"x": 0, "y": 8, "w": 12, "h": 8},
        "targets": [
          {
            "expr": "hippos_active_sessions",
            "legendFormat": "活跃会话"
          }
        ]
      },
      {
        "title": "请求速率",
        "type": "timeseries",
        "gridPos": {"x": 12, "y": 8, "w": 12, "h": 8},
        "targets": [
          {
            "expr": "rate(hippos_requests_total[5m])",
            "legendFormat": "请求速率"
          }
        ]
      }
    ]
  }
}
```

---

## 九、备份与恢复

### 9.1 备份策略

完善的数据备份策略是保障业务连续性的关键。Hippos 采用多层次、全覆盖的备份方案。

#### 9.1.1 备份类型与频率

| 备份类型 | 频率 | 保留期限 | 存储位置 | 说明 |
|---------|------|----------|----------|------|
| 实时备份 | 持续 | 24小时 | 本地 + 远程 | 事务日志增量备份 |
| 全量备份 | 每日 | 7天 | 本地 + 对象存储 | 每日凌晨 2:00 执行 |
| 增量备份 | 每小时 | 3天 | 本地 + 对象存储 | 基于上次全量备份 |
| 归档备份 | 每周 | 1年 | 冷存储 | 长期历史数据归档 |

#### 9.1.2 备份内容

```rust
// 备份任务定义
struct BackupTask {
    // 任务 ID
    task_id: String,
    
    // 备份类型
    backup_type: BackupType,
    
    // 备份范围
    scope: BackupScope,
    
    // 存储目标
    storage_target: StorageTarget,
    
    // 开始时间
    start_time: SystemTime,
    
    // 超时配置
    timeout: Duration,
}

enum BackupType {
    Full,           // 全量备份
    Incremental,    // 增量备份
    Differential,   // 差异备份
    Continuous,     // 持续备份（事务日志）
}

struct BackupScope {
    // 是否备份 SurrealDB 数据
    include_surrealdb: bool,
    
    // 是否备份 LanceDB 索引
    include_lancedb: bool,
    
    // 是否备份配置
    include_config: bool,
    
    // 是否备份审计日志
    include_audit_logs: bool,
    
    // 特定会话列表（空表示全部）
    session_filter: Vec<String>,
}
```

#### 9.1.3 备份实现

```rust
// 备份服务实现
struct BackupService {
    // SurrealDB 备份器
    surrealdb_backup: Arc<SurrealBackup>,
    
    // LanceDB 备份器
    lancedb_backup: Arc<LanceBackup>,
    
    // 存储服务
    storage: Arc<dyn ObjectStorage>,
    
    // 备份元数据存储
    metadata_store: Arc<BackupMetadataStore>,
    
    // 压缩器
    compressor: Box<dyn Compressor>,
}

impl BackupService {
    pub async fn execute_full_backup(&self) -> Result<BackupReport, BackupError> {
        let backup_id = generate_backup_id();
        let start_time = now();
        
        // 1. 暂停写入操作
        self.drain_write_queue().await;
        
        // 2. SurrealDB 全量导出
        let surrealdb_path = format!("/tmp/surrealdb_{}.dump", backup_id);
        self.surrealdb_backup
            .export_full(&surrealdb_path)
            .await?;
        
        // 3. LanceDB 索引导出
        let lancedb_path = format!("/tmp/lancedb_{}.parquet", backup_id);
        self.lancedb_backup
            .export_all(&lancedb_path)
            .await?;
        
        // 4. 压缩备份文件
        let compressed = self.compressor.compress_bulk(&[
            (&surrealdb_path, "surrealdb.dump"),
            (&lancedb_path, "lancedb.index"),
        ])?;
        
        // 5. 计算校验和
        let checksum = calculate_sha256(&compressed);
        
        // 6. 上传到对象存储
        let storage_path = format!("backups/full/{}.tar.gz", backup_id);
        self.storage.upload(&storage_path, &compressed).await?;
        
        // 7. 保存备份元数据
        let metadata = BackupMetadata {
            backup_id,
            backup_type: BackupType::Full,
            created_at: start_time,
            completed_at: now(),
            size_bytes: compressed.len(),
            checksum,
            storage_path,
            retention_days: 7,
        };
        self.metadata_store.save(&metadata).await?;
        
        // 8. 恢复写入操作
        self.resume_write_queue().await;
        
        // 9. 清理本地临时文件
        cleanup_temp_files(&[&surrealdb_path, &lancedb_path]);
        
        Ok(BackupReport {
            backup_id,
            backup_type: BackupType::Full,
            size_bytes: compressed.len(),
            duration: start_time.elapsed()?,
        })
    }
    
    pub async fn execute_incremental_backup(&self, since: SystemTime) -> Result<BackupReport, BackupError> {
        // 增量备份仅导出上次备份后变更的数据
        let backup_id = generate_backup_id();
        
        // 1. 导出变更的 SurrealDB 数据
        let surrealdb_path = format!("/tmp/surrealdb_inc_{}.json", backup_id);
        self.surrealdb_backup
            .export_incremental(since, &surrealdb_path)
            .await?;
        
        // 2. 导出变更的 LanceDB 数据
        let lancedb_path = format!("/tmp/lancedb_inc_{}.parquet", backup_id);
        self.lancedb_backup
            .export_changes_since(since, &lancedb_path)
            .await?;
        
        // 3. 压缩并上传
        let compressed = self.compressor.compress_bulk(&[
            (&surrealdb_path, "changes.json"),
            (&lancedb_path, "vector_changes.parquet"),
        ])?;
        
        let storage_path = format!("backups/incremental/{}.tar.gz", backup_id);
        self.storage.upload(&storage_path, &compressed).await?;
        
        Ok(BackupReport {
            backup_id,
            backup_type: BackupType::Incremental,
            size_bytes: compressed.len(),
            duration: now().duration_since(start_time)?,
        })
    }
}
```

### 9.2 恢复点目标与恢复时间目标

#### 9.2.1 RPO/RTO 定义

| 业务等级 | RPO（恢复点目标） | RTO（恢复时间目标） | 适用场景 |
|---------|-------------------|---------------------|----------|
| 等级一 | ≤ 1 分钟 | ≤ 15 分钟 | 核心业务会话 |
| 等级二 | ≤ 15 分钟 | ≤ 1 小时 | 重要业务会话 |
| 等级三 | ≤ 1 小时 | ≤ 4 小时 | 一般业务会话 |

#### 9.2.2 RPO 保障机制

```rust
// 持续数据保护
struct ContinuousDataProtection {
    // 事务日志存储
    wal_storage: Arc<WalStorage>,
    
    // 日志缓冲区
    log_buffer: Arc<RingBuffer<WALEntry>>,
    
    // 快照间隔
    snapshot_interval: Duration,
    
    // 最大日志保留时间
    max_log_retention: Duration,
}

impl ContinuousDataProtection {
    // 写入事务日志
    pub async fn write_wal(&self, entry: &WALEntry) -> Result<(), Error> {
        // 1. 写入缓冲区
        self.log_buffer.write(entry.clone());
        
        // 2. 异步持久化到存储
        self.wal_storage.append(entry).await?;
        
        // 3. 记录检查点
        self.record_checkpoint().await;
        
        Ok(())
    }
    
    // 恢复到指定时间点
    pub async fn recover_to_point(&self, target_time: SystemTime) -> Result<RecoveryReport, Error> {
        // 1. 找到最近的快照
        let snapshot = self.find_nearest_snapshot(target_time)?;
        
        // 2. 加载快照数据
        let mut data = self.load_snapshot(&snapshot).await?;
        
        // 3. 重放事务日志
        let logs = self.wal_storage.read_since(snapshot.timestamp, target_time)?;
        for log in logs {
            self.apply_log_entry(&mut data, &log)?;
        }
        
        // 4. 验证数据一致性
        self.verify_consistency(&data)?;
        
        Ok(RecoveryReport {
            recovered_from: snapshot.timestamp,
            recovered_to: target_time,
            transactions_replayed: logs.len(),
        })
    }
}
```

#### 9.2.3 RTO 保障机制

```rust
// 恢复流程
struct RecoveryProcedure {
    // 恢复任务队列
    recovery_queue: mpsc::Sender<RecoveryTask>,
    
    // 预定义的恢复剧本
    playbooks: HashMap<RecoveryScenario, RecoveryPlaybook>,
}

struct RecoveryPlaybook {
    // 步骤列表
    steps: Vec<RecoveryStep>,
    
    // 预估恢复时间
    estimated_duration: Duration,
    
    // 前置条件
    prerequisites: Vec<Condition>,
}

impl RecoveryProcedure {
    pub async fn execute_recovery(
        &self,
        scenario: RecoveryScenario,
        target_time: Option<SystemTime>,
    ) -> Result<RecoveryExecution, Error> {
        let playbook = self.playbooks.get(&scenario)
            .ok_or(RecoveryError::UnknownScenario)?;
        
        // 1. 检查前置条件
        self.check_prerequisites(&playbook.prerequisites).await?;
        
        // 2. 创建恢复任务
        let task = RecoveryTask {
            scenario,
            target_time,
            playbook: playbook.clone(),
            started_at: now(),
        };
        
        // 3. 逐步执行恢复步骤
        let mut execution = RecoveryExecution {
            task: task.clone(),
            status: RecoveryStatus::InProgress,
            completed_steps: Vec::new(),
            errors: Vec::new(),
        };
        
        for step in &playbook.steps {
            match self.execute_step(step).await {
                Ok(()) => {
                    execution.completed_steps.push(step.name.clone());
                }
                Err(e) => {
                    execution.errors.push(StepError {
                        step: step.name.clone(),
                        error: e.to_string(),
                    });
                    
                    // 检查是否有回滚步骤
                    if let Some(rollback) = &step.rollback {
                        self.execute_step(rollback).await?;
                    }
                    
                    // 继续执行后续步骤（部分恢复）
                    continue;
                }
            }
        }
        
        // 4. 验证恢复结果
        if self.verify_recovery(&execution).await? {
            execution.status = RecoveryStatus::Completed;
        } else {
            execution.status = RecoveryStatus::Partial;
        }
        
        execution.completed_at = now();
        
        Ok(execution)
    }
}
```

### 9.3 跨区域容灾方案

#### 9.3.1 多活架构设计

```
┌─────────────────────────────────────────────────────────────────────┐
│                      跨区域容灾架构                                  │
└─────────────────────────────────────────────────────────────────────┘

         ┌─────────────────┐
         │   Global Load   │
         │    Balancer     │
         └────────┬────────┘
                  │
     ┌────────────┼────────────┐
     │            │            │
     ▼            ▼            ▼
┌─────────┐  ┌─────────┐  ┌─────────┐
│ Region A│  │ Region B│  │ Region C│
│ (主区域) │  │ (热备)  │  │ (冷备)  │
└────┬────┘  └────┬────┘  └────┬────┘
     │            │            │
     │  实时同步   │  异步同步  │
     │◄──────────►│◄──────────►│
     │            │            │
     ▼            ▼            ▼
┌─────────────────────────────────────────────────────┐
│              分布式存储层                             │
│  ┌───────────┐  ┌───────────┐  ┌───────────┐       │
│  │ SurrealDB │  │ SurrealDB │  │ SurrealDB │       │
│  │  Cluster  │  │  Cluster  │  │  Cluster  │       │
│  └───────────┘  └───────────┘  └───────────┘       │
│         │              │              │            │
│         └──────────────┼──────────────┘            │
│                        ▼                           │
│              ┌─────────────────┐                   │
│              │   Data Proxy    │                   │
│              │  (一致性协调)   │                   │
│              └─────────────────┘                   │
└─────────────────────────────────────────────────────┘
```

#### 9.3.2 同步复制配置

```rust
// 同步复制配置
struct SyncReplicationConfig {
    // 复制目标
    targets: Vec<ReplicationTarget>,
    
    // 复制模式
    mode: ReplicationMode,
    
    // 同步确认策略
    acknowledgment_policy: AckPolicy,
    
    // 超时配置
    timeout: Duration,
}

enum ReplicationMode {
    // 同步复制：所有副本确认后才返回
    Synchronous,
    
    // 半同步：主副本 + 至少一个从副本确认
    SemiSynchronous {
        min_acks: usize,
    },
    
    // 异步复制：主节点立即返回，从节点异步同步
    Asynchronous {
        max_lag: Duration,
    },
}

impl ReplicationService {
    // 同步写入
    pub async fn replicate_write(&self, data: &ReplicationData) -> Result<ReplicationResult, Error> {
        let targets = self.select_replication_targets();
        
        match self.config.mode {
            ReplicationMode::Synchronous => {
                // 等待所有目标确认
                let results = self.write_to_all_targets(data, targets.clone()).await;
                
                // 检查所有写入是否成功
                if results.iter().all(|r| r.is_ok()) {
                    Ok(ReplicationResult::AllAcked)
                } else {
                    Err(ReplicationError::PartialFailure)
                }
            }
            ReplicationMode::SemiSynchronous { min_acks } => {
                // 并行写入所有目标
                let mut results = self.write_to_all_targets(data, targets.clone()).await;
                
                // 统计成功数量
                let success_count = results.iter().filter(|r| r.is_ok()).count();
                
                if success_count >= *min_acks {
                    Ok(ReplicationResult::QuorumAcked)
                } else {
                    Err(ReplicationError::InsufficientAcks)
                }
            }
            ReplicationMode::Asynchronous { .. } => {
                // 主节点立即返回，从节点异步同步
                self.write_to_primary(data).await?;
                
                // 触发异步复制
                self.trigger_async_replication(data, targets).await;
                
                Ok(ReplicationResult::PrimaryAcked)
            }
        }
    }
}
```

#### 9.3.3 故障切换流程

```rust
// 故障切换服务
struct FailoverService {
    // 健康检查器
    health_checker: Arc<HealthChecker>,
    
    // 流量控制器
    traffic_controller: Arc<TrafficController>,
    
    // DNS 管理器
    dns_manager: Arc<DnsManager>,
    
    // 切换决策器
    decision_maker: FailoverDecisionMaker,
}

impl FailoverService {
    // 执行故障切换
    pub async fn execute_failover(&self, from_region: &str, to_region: &str) -> Result<FailoverReport, Error> {
        let report = FailoverReport {
            started_at: now(),
            from_region: from_region.to_string(),
            to_region: to_region.to_string(),
            steps: Vec::new(),
        };
        
        // 1. 确认故障
        let health_status = self.health_checker.check_region_health(from_region).await;
        if health_status.is_healthy() {
            return Err(FailoverError::RegionStillHealthy);
        }
        
        report.add_step("故障确认完成");
        
        // 2. 停止主区域流量
        self.traffic_controller.drain_region(from_region).await?;
        report.add_step("主区域流量已排空");
        
        // 3. 等待数据同步完成
        let sync_status = self.wait_for_sync_completion(to_region).await?;
        report.add_step(&format!("数据同步完成，延迟: {:?}", sync_status.lag));
        
        // 4. 提升从区域为主区域
        self.promote_region(to_region).await?;
        report.add_step("从区域已提升为主区域");
        
        // 5. 更新 DNS 记录
        self.dns_manager.update_global_dns(to_region).await?;
        report.add_step("DNS 记录已更新");
        
        // 6. 验证新主区域
        let verification = self.verify_region_health(to_region).await?;
        if !verification.is_healthy() {
            return Err(FailoverError::PromotionVerificationFailed);
        }
        
        report.completed_at = now();
        report.status = FailoverStatus::Completed;
        
        Ok(report)
    }
}
```

#### 9.3.4 数据一致性保障

```rust
// 冲突解决策略
enum ConflictResolutionPolicy {
    // 最后写入胜出（基于时间戳）
    LastWriterWins,
    
    // 主区域优先
    PrimaryWins { primary_region: String },
    
    // 应用层解决
    ApplicationDefined { resolver: Arc<dyn ConflictResolver> },
    
    // 合并解决
    Merge { merge_strategy: MergeStrategy },
}

// 向量数据合并策略
struct VectorMergeStrategy {
    // 权重计算
    weight_function: Box<dyn Fn(&VectorRecord) -> f64>,
}

impl MergeStrategy for VectorMergeStrategy {
    fn merge_vectors(&self, vectors: &[VectorRecord]) -> VectorRecord {
        // 基于权重计算综合向量
        let weighted_sum: Vec<f32> = (0..vectors[0].dimension)
            .map(|i| {
                vectors.iter()
                    .map(|v| v.embedding[i] * self.weight_function(v))
                    .sum::<f32>()
            })
            .collect();
        
        // 归一化
        let normalized = normalize(&weighted_sum);
        
        VectorRecord {
            embedding: normalized,
            metadata: self.merge_metadata(&vectors),
            timestamp: now(),
        }
    }
}
```

---

## 十、成本控制

### 10.1 冷热数据分层存储策略

合理的数据分层策略可以在保证性能的同时显著降低存储成本。

#### 10.1.1 数据分层定义

```rust
// 数据热度等级
enum DataTier {
    // 热数据：最近活跃访问的数据
    Hot {
        // 保留时间：7天
        retention_days: u32,
        // 存储介质：内存 + NVMe SSD
        storage_type: StorageType::Memory,
        // 索引策略：完整索引
        index_level: IndexLevel::Full,
    },
    
    // 温数据：近期访问但不频繁的数据
    Warm {
        // 保留时间：30天
        retention_days: u32,
        // 存储介质：SSD
        storage_type: StorageType::Ssd,
        // 索引策略：压缩索引
        index_level: IndexLevel::Compressed,
    },
    
    // 冷数据：历史数据，很少访问
    Cold {
        // 保留时间：1年
        retention_days: u365,
        // 存储介质：对象存储
        storage_type: StorageType::ObjectStorage,
        // 索引策略：摘要索引
        index_level: IndexLevel::Summary,
    },
    
    // 归档数据：长期归档
    Archive {
        // 保留时间：7年
        retention_days: u365 * 7,
        // 存储介质：冷存储
        storage_type: StorageType::ColdStorage,
        // 索引策略：无索引
        index_level: IndexLevel::None,
    },
}
```

#### 10.1.2 自动分层机制

```rust
// 数据分层服务
struct TieredStorageService {
    // 当前分层配置
    config: TieredStorageConfig,
    
    // 访问统计
    access_stats: Arc<AccessStatistics>,
    
    // 存储管理器
    storage_manager: Arc<StorageManager>,
    
    // 分层任务调度器
    scheduler: TieredScheduler,
}

impl TieredStorageService {
    // 执行分层检查
    pub async fn execute_tier_check(&self) -> TierCheckReport {
        let mut moved_sessions: Vec<SessionMove> = Vec::new();
        
        // 检查每个会话的数据热度
        for session in self.get_active_sessions().await {
            let hotness = self.calculate_session_hotness(&session).await;
            
            // 确定目标层级
            let target_tier = self.determine_target_tier(&hotness);
            
            // 如果需要移动
            if session.current_tier != target_tier {
                let movement = self.move_session_to_tier(&session, target_tier).await;
                moved_sessions.push(movement);
            }
        }
        
        TierCheckReport {
            checked_at: now(),
            sessions_checked: self.active_session_count(),
            moved_sessions,
            estimated_savings: self.calculate_savings(&moved_sessions),
        }
    }
    
    // 计算会话热度分数
    async fn calculate_session_hotness(&self, session: &Session) -> HotnessScore {
        let recent_accesses = self.access_stats
            .get_access_count(&session.id, Duration::from_days(7))
            .await;
        
        let older_accesses = self.access_stats
            .get_access_count(&session.id, Duration::from_days(30))
            .await;
        
        let vector_count = self.vector_index.count(&session.id).await;
        
        HotnessScore {
            recent_access_frequency: recent_accesses as f64 / 7.0,
            access_trend: self.calculate_trend(recent_accesses, older_accesses),
            data_freshness: now() - session.last_active_at,
            vector_volume: vector_count,
        }
    }
    
    // 移动数据到目标层级
    async fn move_session_to_tier(&self, session: &Session, target_tier: DataTier) -> SessionMove {
        let start_time = now();
        
        match target_tier {
            DataTier::Hot => {
                // 从冷/归档恢复到热存储
                self.storage_manager.move_to_memory(&session).await?;
            }
            DataTier::Warm => {
                // 从热存储迁移到 SSD
                self.storage_manager.move_to_ssd(&session).await?;
            }
            DataTier::Cold => {
                // 迁移到对象存储，压缩索引
                self.storage_manager.move_to_object_storage(&session, IndexLevel::Compressed).await?;
            }
            DataTier::Archive => {
                // 迁移到冷存储，移除索引
                self.storage_manager.move_to_archive(&session).await?;
            }
        }
        
        let move_cost = self.storage_manager.estimate_move_cost(session, &target_tier);
        
        SessionMove {
            session_id: session.id.clone(),
            from_tier: session.current_tier,
            to_tier: target_tier,
            started_at: start_time,
            completed_at: now(),
            data_moved_bytes: move_cost.data_size,
        }
    }
}
```

### 10.2 自动归档机制

#### 10.2.1 归档策略配置

```rust
// 归档策略
struct ArchivePolicy {
    // 策略名称
    name: String,
    
    // 触发条件
    triggers: Vec<ArchiveTrigger>,
    
    // 归档格式
    format: ArchiveFormat,
    
    // 存储目标
    storage_target: StorageTarget,
    
    // 保留策略
    retention_policy: RetentionPolicy,
}

enum ArchiveTrigger {
    // 基于时间
    TimeBased { inactive_days: u32 },
    
    // 基于大小
    SizeBased { max_size_bytes: u64 },
    
    // 基于访问频率
    AccessBased { max_access_per_day: u64 },
    
    // 手动触发
    Manual,
}

enum ArchiveFormat {
    // Tar + Gzip
    TarGzip { compression_level: i32 },
    
    // Parquet（适用于向量化数据）
    Parquet { row_group_size: usize },
    
    // Zstd（高压缩比）
    Zstd { level: u32 },
}
```

#### 10.2.2 归档执行流程

```rust
// 归档服务
struct ArchiveService {
    // 归档策略
    policies: Vec<ArchivePolicy>,
    
    // 会话管理器
    session_manager: Arc<SessionManager>,
    
    // 存储服务
    storage: Arc<dyn StorageBackend>,
    
    // 归档存储
    archive_storage: Arc<dyn ArchiveStorage>,
}

impl ArchiveService {
    // 执行归档任务
    pub async fn execute_archive(&self, policy_name: &str) -> Result<ArchiveReport, Error> {
        let policy = self.policies.iter()
            .find(|p| p.name == policy_name)
            .ok_or(ArchiveError::PolicyNotFound)?;
        
        let mut archived_sessions: Vec<ArchivedSession> = Vec::new();
        let mut errors: Vec<ArchiveErrorDetail> = Vec::new();
        
        // 查找符合条件的会话
        let sessions = self.find_sessions_for_archive(policy).await;
        
        for session in sessions {
            match self.archive_session(&session, policy).await {
                Ok(archived) => {
                    archived_sessions.push(archived);
                    
                    // 清理原始数据
                    self.cleanup_original_data(&session).await;
                }
                Err(e) => {
                    errors.push(ArchiveErrorDetail {
                        session_id: session.id.clone(),
                        error: e.to_string(),
                    });
                }
            }
        }
        
        Ok(ArchiveReport {
            policy_name: policy_name.to_string(),
            archived_count: archived_sessions.len(),
            failed_count: errors.len(),
            total_size_bytes: archived_sessions.iter().map(|s| s.size_bytes).sum(),
            archived_sessions,
            errors,
        })
    }
    
    // 归档单个会话
    async fn archive_session(&self, session: &Session, policy: &ArchivePolicy) -> Result<ArchivedSession, Error> {
        let start_time = now();
        
        // 1. 导出会话数据
        let export = self.export_session_data(session).await?;
        
        // 2. 压缩数据
        let compressed = self.compress_data(&export, &policy.format)?;
        
        // 3. 计算校验和
        let checksum = calculate_sha256(&compressed);
        
        // 4. 生成归档文件名
        let archive_name = format!(
            "sessions/{}/{:year:04}/{:month:02}/{:day:02}/{}.tar.gz",
            session.tenant_id,
            chrono::Local::now(),
            session.id
        );
        
        // 5. 上传到归档存储
        self.archive_storage.upload(&archive_name, &compressed).await?;
        
        // 6. 生成索引文件
        let index = self.generate_archive_index(session, &compressed);
        self.archive_storage.upload(&format!("{}.index.json", archive_name), &index).await?;
        
        // 7. 更新会话状态
        self.session_manager.mark_archived(&session.id, &archive_name).await?;
        
        Ok(ArchivedSession {
            session_id: session.id.clone(),
            archive_path: archive_name,
            size_bytes: compressed.len(),
            checksum,
            archived_at: now(),
        })
    }
}
```

### 10.3 资源配额管理

#### 10.3.1 配额配置模型

```rust
// 租户配额配置
struct TenantQuota {
    // 租户 ID
    tenant_id: String,
    
    // 会话配额
    session_quota: SessionQuota,
    
    // 存储配额
    storage_quota: StorageQuota,
    
    // 计算配额
    compute_quota: ComputeQuota,
    
    // API 调用配额
    api_quota: ApiQuota,
}

struct SessionQuota {
    // 最大会话数
    max_sessions: u64,
    
    // 每会话最大轮次数
    max_turns_per_session: u64,
    
    // 最大并发会话数
    max_concurrent_sessions: u64,
}

struct StorageQuota {
    // 总存储空间（字节）
    total_bytes: u64,
    
    // 热数据存储配额
    hot_bytes: u64,
    
    // 温数据存储配额
    warm_bytes: u64,
    
    // 冷数据存储配额
    cold_bytes: u64,
}

struct ComputeQuota {
    // 每秒最大请求数（QPS）
    max_qps: u64,
    
    // 并发查询限制
    max_concurrent_queries: u64,
    
    // 每月最大计算资源使用量
    monthly_compute_units: u64,
}

struct ApiQuota {
    // 每分钟最大调用数
    calls_per_minute: u64,
    
    // 每小时最大调用数
    calls_per_hour: u64,
    
    // 每日最大调用数
    calls_per_day: u64,
}
```

#### 10.3.2 配额执行引擎

```rust
// 配额执行器
struct QuotaEnforcer {
    // 配额存储
    quota_store: Arc<dyn QuotaStore>,
    
    // 使用量追踪器
    usage_tracker: Arc<UsageTracker>,
    
    // 配额超限处理器
    quota_handler: Box<dyn QuotaViolationHandler>,
}

impl QuotaEnforcer {
    // 检查并消耗配额
    pub async fn check_and_consume(
        &self,
        tenant_id: &str,
        resource_type: ResourceType,
        amount: u64,
    ) -> Result<ConsumptionResult, QuotaError> {
        // 1. 获取当前配额
        let quota = self.quota_store.get_quota(tenant_id, resource_type).await?;
        
        // 2. 获取当前使用量
        let current_usage = self.usage_tracker.get_usage(tenant_id, resource_type).await?;
        
        // 3. 检查是否超限
        if current_usage + amount > quota.limit {
            // 超限处理
            return self.handle_quota_exceeded(tenant_id, resource_type, current_usage, quota).await;
        }
        
        // 4. 消耗配额
        self.usage_tracker.increment(tenant_id, resource_type, amount).await?;
        
        Ok(ConsumptionResult {
            resource_type,
            consumed: amount,
            remaining: quota.limit - current_usage - amount,
            reset_at: quota.reset_time,
        })
    }
    
    // 处理配额超限
    async fn handle_quota_exceeded(
        &self,
        tenant_id: &str,
        resource_type: ResourceType,
        current_usage: u64,
        quota: TenantQuota,
    ) -> Result<ConsumptionResult, QuotaError> {
        // 记录违规事件
        self.usage_tracker.record_violation(ViolationEvent {
            tenant_id: tenant_id.to_string(),
            resource_type,
            attempted_amount: quota.limit - current_usage,
            limit: quota.limit,
            occurred_at: now(),
        });
        
        // 根据策略处理
        match quota.violation_policy {
            QuotaViolationPolicy::Reject => {
                Err(QuotaError::LimitExceeded {
                    resource_type,
                    current: current_usage,
                    limit: quota.limit,
                })
            }
            QuotaViolationPolicy::Queue { max_queue_size } => {
                // 将请求加入等待队列
                self.enqueue_for_processing(tenant_id, resource_type, max_queue_size).await;
                Ok(ConsumptionResult {
                    resource_type,
                    consumed: 0,
                    remaining: 0,
                    queued: true,
                })
            }
            QuotaViolationPolicy::UpgradePrompt => {
                // 返回提示信息，引导升级
                Err(QuotaError::UpgradeRequired {
                    resource_type,
                    current: current_usage,
                    limit: quota.limit,
                    upgrade_url: quota.upgrade_url.clone(),
                })
            }
        }
    }
}
```

#### 10.3.3 配额监控与告警

```rust
// 配额监控服务
struct QuotaMonitoringService {
    // 配额存储
    quota_store: Arc<dyn QuotaStore>,
    
    // 使用量追踪器
    usage_tracker: Arc<UsageTracker>,
    
    // 告警发送器
    alert_sender: Arc<dyn AlertSender>,
}

impl QuotaMonitoringService {
    // 定期检查配额使用情况
    pub async fn run_quota_monitoring(&self) {
        let mut interval = tokio::time::interval(Duration::from_hours(1));
        
        loop {
            interval.tick().await;
            self.check_all_quotas().await;
        }
    }
    
    async fn check_all_quotas(&self) {
        let tenants = self.quota_store.list_tenants().await;
        
        for tenant in tenants {
            self.check_tenant_quotas(&tenant).await;
        }
    }
    
    async fn check_tenant_quotas(&self, tenant_id: &str) {
        let usage = self.usage_tracker.get_all_usage(tenant_id).await;
        let quotas = self.quota_store.get_all_quotas(tenant_id).await;
        
        for (resource_type, current_usage) in usage {
            if let Some(quota) = quotas.get(&resource_type) {
                let usage_ratio = current_usage as f64 / quota.limit as f64;
                
                // 根据使用比例触发告警
                match usage_ratio {
                    r if r >= 1.0 => {
                        self.alert_sender.send(QuotaAlert {
                            tenant_id,
                            resource_type,
                            level: AlertLevel::Critical,
                            message: format!("配额已用尽: {}%", (r * 100.0) as u64),
                        }).await;
                    }
                    r if r >= 0.9 => {
                        self.alert_sender.send(QuotaAlert {
                            tenant_id,
                            resource_type,
                            level: AlertLevel::Warning,
                            message: format!("配额使用率已达 90%"),
                        }).await;
                    }
                    r if r >= 0.8 => {
                        self.alert_sender.send(QuotaAlert {
                            tenant_id,
                            resource_type,
                            level: AlertLevel::Info,
                            message: format!("配额使用率已达 80%"),
                        }).await;
                    }
                    _ => {}  // 正常使用，无需告警
                }
            }
        }
    }
}
```

#### 10.3.4 成本优化建议

```rust
// 成本优化服务
struct CostOptimizationService {
    // 使用量分析器
    usage_analyzer: UsageAnalyzer,
    
    // 存储服务
    storage_service: Arc<StorageService>,
    
    // 推荐引擎
    recommendation_engine: RecommendationEngine,
}

impl CostOptimizationService {
    // 生成成本优化报告
    pub async fn generate_optimization_report(&self, tenant_id: &str) -> OptimizationReport {
        // 分析存储使用模式
        let storage_analysis = self.usage_analyzer.analyze_storage_patterns(tenant_id).await;
        
        // 分析访问模式
        let access_analysis = self.usage_analyzer.analyze_access_patterns(tenant_id).await;
        
        // 生成优化建议
        let recommendations = self.recommendation_engine.generate(&storage_analysis, &access_analysis);
        
        // 计算预期节省
        let estimated_savings = self.calculate_savings(&recommendations, &storage_analysis);
        
        OptimizationReport {
            tenant_id,
            generated_at: now(),
            current_monthly_cost: self.calculate_current_cost(tenant_id).await,
            estimated_monthly_savings: estimated_savings,
            recommendations,
            action_items: self.prioritize_actions(&recommendations),
        }
    }
    
    // 推荐冷却存储策略
    fn recommend_tier_migration(&self, analysis: &StorageAnalysis) -> Vec<TierMigrationRecommendation> {
        let mut recommendations = Vec::new();
        
        for (session_id, session_storage) in &analysis.session_storage {
            // 分析访问频率
            let access_frequency = analysis.get_access_frequency(session_id);
            
            // 如果访问频率低，建议迁移到冷存储
            if access_frequency < 0.1 && session_storage.hot_data_ratio > 0.5 {
                recommendations.push(TierMigrationRecommendation {
                    session_id: session_id.clone(),
                    current_tier: DataTier::Hot,
                    recommended_tier: DataTier::Cold,
                    estimated_savings: self.estimate_savings(session_storage, DataTier::Cold),
                    priority: RecommendationPriority::High,
                });
            }
        }
        
        recommendations
    }
}
```

---

## 十一、扩展性考虑

### 11.1 水平扩展策略

系统设计支持多个维度的水平扩展：

**无状态服务扩展**。API 服务层设计为无状态，可以通过增加实例数量来提升吞吐能力。会话状态通过共享存储和缓存层管理，不依赖本地状态。

```rust
// 无状态服务设计
#[derive(Clone)]
pub struct ApiService {
    // 所有状态通过依赖注入，不保留在服务实例中
    storage: Arc<dyn StorageBackend>,
    cache: Arc<dyn CacheBackend>,
    index: Arc<dyn IndexBackend>,
    metrics: Arc<MetricsCollector>,
}
```

**分片策略**。当单节点存储能力受限时，可以实施数据分片：

```rust
// 会话分片策略
struct ShardedStorage {
    // 分片映射
    shards: Vec<Shard>,
    
    // 分片选择函数
    sharding_fn: fn(&str) -> usize,
}

impl ShardedStorage {
    pub fn select_shard(&self, session_id: &str) -> &Shard {
        let shard_index = (self.sharding_fn)(session_id);
        &self.shards[shard_index % self.shards.len()]
    }
    
    // 基于一致性哈希的分片
    pub fn consistent_hash_shard(session_id: &str, shard_count: usize) -> usize {
        let hash = xxhash64(session_id);
        (hash as usize) % shard_count
    }
}
```

### 11.2 功能扩展方向

**多模态支持**。未来可以扩展支持图像、音频等多模态内容的存储和检索。LanceDB 原生支持多模态数据，可以平滑演进。

**实时协作**。支持多用户实时协作编辑同一会话，实现类似 Google Docs 的协作体验。

**知识图谱增强**。利用 SurrealDB 的图数据库能力，构建对话实体之间的关联关系，支持更复杂的知识推理。

**联邦学习**。支持跨会话的知识迁移和模型微调，在保护隐私的前提下提升摘要和检索质量。

### 11.3 性能演进路线

**当前版本（v1.0）**：
- 单节点 SurrealDB + LanceDB 嵌入模式
- 目标：验证核心功能，性能满足基本需求

**v1.x 演进**：
- SurrealDB 集群模式
- Redis 分布式缓存
- 目标：支持更大规模的会话和更高的并发

**v2.0 规划**：
- 向量索引服务独立部署
- 多级缓存架构
- GPU 加速的向量检索
- 目标：P99 < 5ms，支持亿级向量

---

## 附录 A：术语表

| 术语 | 定义 |
|------|------|
| 脱水 (Dehydration) | 将原始对话压缩为轻量级索引的过程 |
| 注水 (Rehydration) | 根据索引从存储加载完整内容的过程 |
| 会话孤仓 (Session Silo) | 完全隔离的会话数据空间 |
| 渐进式披露 (Progressive Disclosure) | 按需逐步暴露详细内容的机制 |
| 近似最近邻 (ANN) | 高维向量空间中寻找近似相似向量的算法 |
| IVF | Inverted File Index，向量索引的一种结构 |
| PQ | Product Quantization，向量量化压缩技术 |
| RPO | Recovery Point Objective，恢复点目标 |
| RTO | Recovery Time Objective，恢复时间目标 |
| KMS | Key Management Service，密钥管理服务 |
| HSM | Hardware Security Module，硬件安全模块 |
| WAL | Write-Ahead Log，预写日志 |

---

## 附录 B：API 完整规范

### B.1 MCP 工具定义

```json
{
  "tools": [
    {
      "name": "list_recent_indices",
      "description": "获取当前会话最近的对话摘要列表，支持渐进式披露上下文而不加载完整内容",
      "inputSchema": {
        "type": "object",
        "properties": {
          "limit": {
            "type": "integer",
            "description": "返回的最大索引数量（默认10，最大100）",
            "minimum": 1,
            "maximum": 100
          }
        }
      },
      "outputSchema": {
        "type": "object",
        "properties": {
          "indices": {
            "type": "array",
            "items": {"$ref": "#/$defs/IndexRecord"}
          },
          "total_count": {"type": "integer"}
        }
      }
    },
    {
      "name": "search_indices",
      "description": "在当前会话内使用语义相似度或关键词搜索对话索引",
      "inputSchema": {
        "type": "object",
        "properties": {
          "query": {"type": "string", "description": "搜索查询文本或语义描述"},
          "limit": {"type": "integer", "description": "最大结果数量（默认10，最大50）"},
          "time_range": {
            "type": "object",
            "description": "可选的时间范围过滤器"
          }
        },
        "required": ["query"]
      }
    },
    {
      "name": "fetch_turn_content",
      "description": "获取特定对话轮次的完整原始内容",
      "inputSchema": {
        "type": "object",
        "properties": {
          "turn_id": {"type": "string", "description": "要检索的对话轮次唯一标识符"}
        },
        "required": ["turn_id"]
      }
    },
    {
      "name": "store_turn",
      "description": "存储

<task_metadata>
session_id: ses_4581ad671ffeGM9L5Derallt3j
</task_metadata>